{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducció a la pràctica 1: primers passos\n",
    "\n",
    "## Objectius\n",
    "\n",
    "Els objectius d'aquesta pràctica són:\n",
    "\n",
    "* Aplicar models de regressió, ficant l'èmfasi en: \n",
    "    1. Analitzar els atributs per seleccionar els més representatius i normalitzar-los.\n",
    "    2. Avaluar correctament l'error del model \n",
    "    3. Visualitzar les dades i el model resultant\n",
    "    4. Saber aplicar el procès de descens del gradient\n",
    "\n",
    "* Ésser capaç d'aplicar tècniques de regressió en casos reals\n",
    "\n",
    "* Validar els resultats en dades reals\n",
    "\n",
    "* Fomentar la capacitat per presentar resultats tècnics d'aprenentatge computacional de forma adequada davant altres persones\n",
    "\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "Aquest ``jupyter notebook`` està compost de blocs de text i codi, recordeu que hi ha blocs de codi que depenen de que blocs anteriors hagin estat executats. \n",
    "\n",
    "El codi d'aquest notebook és modificable i us recomanem que feu canvis i en comproveu els resultats.\n",
    "\n",
    "**Per a executar el notebook: cal que instal.leu [jupyter notebook](http://jupyter.readthedocs.io/en/latest/install.html).**\n",
    "\n",
    "\n",
    "### Guia d'instal.lació de les llibreries\n",
    "\n",
    "\n",
    "És molt recomanable que utilitzeu Linux, ja que agilitza la instal.lació de les llibreries. També es recomana utilitzar **Anaconda**, una distribucó de python multiplataforma que permet instal.lar llibreries fàcilment i l'IDE d'spyder o PyCharm.\n",
    "\n",
    "Donat que teniu conda o pypi (pip) (aquest segon es pot instal.lar amb ``apt-get``), heu d'instal.lar els següents paquets (exemple en pypi):\n",
    "\n",
    "```\n",
    "sudo pip install numpy\n",
    "sudo pip install scikit-learn\n",
    "sudo pip install matplotlib\n",
    "sudo pip install scipy\n",
    "```\n",
    "\n",
    "En el cas d'Anaconda, substituir ``sudo pip`` per ``conda``.\n",
    "\n",
    "En el cas del matplotlib, si us dona errors en Ubuntu Linux (`FileNotFoundError: [Errno 2] No such file or directory: 'latex': 'latex'`), cal instal·lar el paquet `texlive-full` (`sudo apt install texlive-full`) que ocupa 3-4GB. Si només ho voleu per aquesta pràctica, podeu provar amb el `textlive-base` (uns 100MB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació i entregues de la pràctica 1\n",
    "\n",
    "En la pràctica 1, es presenten diversos problemes per comprendre els mètodes de regressió numèrica. \n",
    "\n",
    "Les entregues s'organitzen en tres nivells d'assoliment dels objectius, incrementals: apartat **C (sobre 5 punts)**, assoliment baix, apartat **B, (sobre 3 punts)**, assoliment mig i apartat **A, (sobre 2 punts)**, assoliment alt. La suma dels 3 apartats serà la nota final de la pràctica 1.\n",
    "\n",
    "Per aprovar la pràctica és requisit necessari completar satisfactòriament els problemes d'assoliment baix (C), demostrant així una comprensió mínima de la matèria. Per tant, la superació de la pràctica 1 estarà condicionada a la presentació de la documentació sobre l'apartat (C), i serà opcional realitzar els apartats (B i A).\n",
    "\n",
    "Resumint, la pràctica 1 conté 3 apartats:\n",
    "\n",
    "* apartat C. serà obligatori per aprovar la pràctica 1 (amb un 5.0)\n",
    "* apartat B. serà opcional i val fins a 3 punts (cal haver fet el apartat C).\n",
    "* apartat A. serà opcional i val fins a 2 punts (cal haver fet el apartat C i B).\n",
    "\n",
    "\n",
    "### Sessió de treball i sessió d'avaluació\n",
    "\n",
    "La sessió de treball del 29 de setembre, està orientada a que els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les bases de dades que us han estat assignades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades.\n",
    "\n",
    "En definitiva, l'objectiu de la sessió de treball és que al sortir tingueu clar com són les vostres dades, què cal entregar i com implementar cada apartat C, B i A. \n",
    "\n",
    "En la següent sessió d'avaluació del 13 d'octubre, la màxima puntuació per la **pràctica 1 de regressió** s'aconsegueix resolent els problemes dels apartats (B i A), d'entrega opcional. Caldrà pujar al Caronte abans de les 23:59h del dimecres 12 d'octubre un ZIP amb el codi, la documentació i el ppt (10 minuts).\n",
    "\n",
    "* Entrega ZIP \n",
    "   1. Memòria explicant els resultats trobats en la base de dades que heu treballat, detallant el passos seguits (60% de la nota). \n",
    "   2. Codi python desenvolupat (30% de la nota)\n",
    "   3. Presentació amb els resultats 10 min màxim (10% de la nota)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material de la pràctica 1\n",
    "\n",
    "1. Bases de dades a Kaggle: cada grup utilitzarà les bases de dades que se li hagin assignat. \n",
    "2. Codi d'exemple (aquest document).\n",
    "3. Apunts de l'assignatura.\n",
    "4. Llibreries de python: scikit-learn, numpy, scipy, matplotlib.\n",
    "\n",
    "### Bases de Dades\n",
    "\n",
    "| #  | URL                                                                      | GRUP        |\n",
    "|----|--------------------------------------------------------------------------|-------------|\n",
    "| 1  | https://www.kaggle.com/mohansacharya/graduate-admissions                 | GPA101-0830 |\n",
    "| 2  | https://www.kaggle.com/primaryobjects/voicegender                        | GPA102-0830 |\n",
    "| 3  | https://www.kaggle.com/mirichoi0218/insurance                            | GPA103-0830 |\n",
    "| 4  | https://www.kaggle.com/rhuebner/human-resources-data-set                 | GPA104-0830 |\n",
    "| 5  | https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009          | GPA105-0830 |\n",
    "| 6  | https://www.kaggle.com/kumarajarshi/life-expectancy-who                  | GPA201-0930 |\n",
    "| 7  | https://www.kaggle.com/marklvl/bike-sharing-dataset                      | GPA202-0930 |\n",
    "| 8  | https://www.kaggle.com/vikrishnan/boston-house-prices                    | GPA203-0930 |\n",
    "| 9  | https://www.kaggle.com/imnikhilanand/heart-attack-prediction             | GPA204-0930 |\n",
    "| 10 | https://www.kaggle.com/dongeorge/beer-consumption-sao-paulo              | GPA205-0930 |\n",
    "| 11 | https://www.kaggle.com/anderas/car-consume                               | GPA301-1030 |\n",
    "| 12 | https://www.kaggle.com/edgarhuichen/nba-players-career-game-log          | GPA302-1030 |\n",
    "| 13 | https://www.kaggle.com/dipam7/student-grade-prediction                   | GPA303-1030 |\n",
    "| 14 | https://www.kaggle.com/navoneel/fta-data                                 | GPA304-1030 |\n",
    "| 15 | https://www.kaggle.com/maajdl/yeh-concret-data                           | GPA305-1030 |\n",
    "| 16 | https://www.kaggle.com/mrisdal/combo17-galaxy-dataset                    | GPA401-1130 |\n",
    "| 17 | https://www.kaggle.com/elikplim/forest-fires-data-set                    | GPA402-1130 |\n",
    "| 18 | https://www.kaggle.com/rodolfomendes/abalone-dataset                     | GPA403-1130 |\n",
    "| 19 | https://www.kaggle.com/ravisane1/market-price-of-onion-2020              | GPA404-1130 |\n",
    "| 20 | https://www.kaggle.com/fredgirod/web-crawler-for-real-estate-market      | GPA405-1130 |\n",
    "| 21 | https://www.kaggle.com/avikasliwal/used-cars-price-prediction            | GPA501-1230 |\n",
    "| 22 | https://www.kaggle.com/shebrahimi/financial-distress                     | GPA502-1230 |\n",
    "| 23 | https://www.kaggle.com/usda/the-national-summary-of-meats                | GPA503-1230 |\n",
    "| 24 | https://www.kaggle.com/uciml/electric-power-consumption-data-set         | GPA504-1230 |\n",
    "| 25 | https://www.kaggle.com/manishkc06/engineering-graduate-salary-prediction | GPA505-1230 |\n",
    "| 26 | https://www.kaggle.com/jsphyg/tipping                                    | GPA601-1530 |\n",
    "| 27 | https://www.kaggle.com/amarpandey/world-life-expectancy-18002016         | GPA602-1530 |\n",
    "| 28 | https://www.kaggle.com/snehal1405/yellow-stone-national-park             | GPA603-1530 |\n",
    "| 29 | https://www.kaggle.com/nisargpatel/automobiles                           | GPA604-1530 |\n",
    "| 30 | https://www.kaggle.com/sabermalek/tapds                                  | GPA605-1530 |\n",
    "| 31 | https://www.kaggle.com/noordeen/insurance-premium-prediction             | GPA606-1530 |\n",
    "| 32 | https://www.kaggle.com/olgabelitskaya/russian-financial-indicators       | GPA607-1530 |\n",
    "| 33 | https://www.kaggle.com/ramkumarr02/deodorant-instant-liking-data         | GPA608-1530 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (C): Analitzant Dades\n",
    "\n",
    "L'objectiu d'aquest primer apartat serà conèixer la base de dades que es té entre mans. S'han d'analitzar els diferents atributs que la composen, entendre'ls i, si no està estipulat, **caldrà fixar quin es l'atribut objectiu a predir de tots els que hi ha a la base de dades**, justificant el per què de la decisió (és útil i representatiu pel problema, per exemple, donat un conjunt de dades sobre persones: edat, gènere, pes, alçada, risc de patir càncer, aquesta última pot ser justificada com la de més interés). També podeu mirar que l'atribut objectiu tingui valors que canvien. Per exemple, no té sentit predir un atribut on el 99% dels valors són 0, i hi ha algun 1.\n",
    "\n",
    "Ara podeu veure un exemple amb una base de dades **dummy** que creem nosaltres mateixos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalitat de la BBDD: (134, 30)\n",
      "Dimensionalitat de les entrades X (134, 2)\n",
      "Dimensionalitat de l'atribut Y (134,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "# Visualitzarem només 3 decimals per mostra\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Funcio per a llegir dades en format csv\n",
    "def load_dataset(path):\n",
    "    dataset = pd.read_csv(path, header=0, delimiter=',')\n",
    "    return dataset\n",
    "\n",
    "# Carreguem dataset d'exemple\n",
    "dataset = load_dataset(\"data/Beef History.csv\")\n",
    "data = dataset.values\n",
    "\n",
    "x = data[:, :2]\n",
    "y = data[:, 2]\n",
    "\n",
    "print(\"Dimensionalitat de la BBDD:\", dataset.shape)\n",
    "print(\"Dimensionalitat de les entrades X\", x.shape)\n",
    "print(\"Dimensionalitat de l'atribut Y\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunes bases de dades tenen valors no existents. Numpy els representa amb ``np.nan``. Per a treure'ls, podeu fer: ``dades[np.isnan(dades)] = valor``. Podeu mirar com afecten diferents estratègies d'assignar ``valor``. Per exemple, pot ser 0, la mitja, la mediana, .... També podeu analitzar si hi ha algun atribut perdut (que té molts valors no existents) i valorar si eliminar directament l'atribut.\n",
    "\n",
    "Hi ha vegades que el fitxer .csv utilitza una coma ',' en comptes d'un punt decimal '.', fent que cada atribut sigui considerat com un ``string``. Per tant, a part d'eliminar les files (mostres) que continguin ``NaN``, cal convertir les ',' a '.' per a poder convertir els valors a ``float``.\n",
    "\n",
    "A més, utilitzeu la llibreria pandas, i no `np.genfromtxt()` ja que llegeix només valors numèrics, i els NaN els converteix a string. Si esteu empenyats en utilitzar `np.genfromtxt()`, caldrà posar-li com a paràmetre `dtype=object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per comptar el nombre de valors no existents:\n",
      "YEAR                                42\n",
      "POUNDS GRADED                       49\n",
      "PRIME                               70\n",
      "%                                   70\n",
      "CHOICE                              65\n",
      "%.1                                 65\n",
      "SELECT                              65\n",
      "%.2                                 65\n",
      "STNDRD                              78\n",
      "%.3                                 78\n",
      "COMRCL                              69\n",
      "%.4                                 69\n",
      "UTILITY                             67\n",
      "%.5                                 67\n",
      "CUTTER                              92\n",
      "%.6                                 92\n",
      "CANNER                             111\n",
      "%.7                                111\n",
      "S/H                                101\n",
      "%  of FEDERAL  SLAUGHTER\\t BEEF     49\n",
      "Y1                                  86\n",
      "%.8                                 87\n",
      "Y2                                  87\n",
      "%.9                                 87\n",
      "Y3                                  87\n",
      "%.10                                87\n",
      "Y4                                  87\n",
      "%.11                                87\n",
      "Y5                                  87\n",
      "%.12                                87\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Per comptar el nombre de valors no existents:\")\n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'str'>\n",
      "Per comptar el nombre de valors no existents:\n",
      "YEAR                                0\n",
      "POUNDS GRADED                       1\n",
      "PRIME                              22\n",
      "%                                  22\n",
      "CHOICE                             17\n",
      "%.1                                17\n",
      "SELECT                             17\n",
      "%.2                                17\n",
      "STNDRD                             30\n",
      "%.3                                30\n",
      "COMRCL                             21\n",
      "%.4                                21\n",
      "UTILITY                            19\n",
      "%.5                                19\n",
      "CUTTER                             44\n",
      "%.6                                44\n",
      "CANNER                             63\n",
      "%.7                                63\n",
      "S/H                                53\n",
      "%  of FEDERAL  SLAUGHTER\\t BEEF     1\n",
      "Y1                                 38\n",
      "%.8                                39\n",
      "Y2                                 39\n",
      "%.9                                39\n",
      "Y3                                 39\n",
      "%.10                               39\n",
      "Y4                                 39\n",
      "%.11                               39\n",
      "Y5                                 39\n",
      "%.12                               39\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POUNDS GRADED</th>\n",
       "      <th>PRIME</th>\n",
       "      <th>%</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>%.1</th>\n",
       "      <th>SELECT</th>\n",
       "      <th>%.2</th>\n",
       "      <th>STNDRD</th>\n",
       "      <th>%.3</th>\n",
       "      <th>COMRCL</th>\n",
       "      <th>%.4</th>\n",
       "      <th>UTILITY</th>\n",
       "      <th>%.5</th>\n",
       "      <th>CUTTER</th>\n",
       "      <th>%.6</th>\n",
       "      <th>CANNER</th>\n",
       "      <th>%.7</th>\n",
       "      <th>S/H</th>\n",
       "      <th>%  of FEDERAL  SLAUGHTER\\t BEEF</th>\n",
       "      <th>Y1</th>\n",
       "      <th>%.8</th>\n",
       "      <th>Y2</th>\n",
       "      <th>%.9</th>\n",
       "      <th>Y3</th>\n",
       "      <th>%.10</th>\n",
       "      <th>Y4</th>\n",
       "      <th>%.11</th>\n",
       "      <th>Y5</th>\n",
       "      <th>%.12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1930</td>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1931</td>\n",
       "      <td>159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1932</td>\n",
       "      <td>208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1933</td>\n",
       "      <td>238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1934</td>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1935</td>\n",
       "      <td>268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1936</td>\n",
       "      <td>450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1937</td>\n",
       "      <td>408</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1938</td>\n",
       "      <td>598</td>\n",
       "      <td>27</td>\n",
       "      <td>4.5%</td>\n",
       "      <td>283</td>\n",
       "      <td>47.3%</td>\n",
       "      <td>187</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>9.0%</td>\n",
       "      <td>34</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>11</td>\n",
       "      <td>1.8%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.33%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1939</td>\n",
       "      <td>509</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>232</td>\n",
       "      <td>45.6%</td>\n",
       "      <td>176</td>\n",
       "      <td>34.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>10.8%</td>\n",
       "      <td>29</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>6</td>\n",
       "      <td>1.2%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1940</td>\n",
       "      <td>579</td>\n",
       "      <td>12</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>230</td>\n",
       "      <td>39.7%</td>\n",
       "      <td>234</td>\n",
       "      <td>40.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69</td>\n",
       "      <td>11.9%</td>\n",
       "      <td>25</td>\n",
       "      <td>4.3%</td>\n",
       "      <td>7</td>\n",
       "      <td>1.2%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1941</td>\n",
       "      <td>789</td>\n",
       "      <td>13</td>\n",
       "      <td>1.6%</td>\n",
       "      <td>308</td>\n",
       "      <td>39.0%</td>\n",
       "      <td>344</td>\n",
       "      <td>43.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86</td>\n",
       "      <td>10.9%</td>\n",
       "      <td>26</td>\n",
       "      <td>3.3%</td>\n",
       "      <td>9</td>\n",
       "      <td>1.1%</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.38%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1942</td>\n",
       "      <td>1,478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439</td>\n",
       "      <td>29.7%</td>\n",
       "      <td>560</td>\n",
       "      <td>37.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>284</td>\n",
       "      <td>19.2%</td>\n",
       "      <td>173</td>\n",
       "      <td>11.7%</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0.47%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1943</td>\n",
       "      <td>6,691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,297</td>\n",
       "      <td>19.4%</td>\n",
       "      <td>2,081</td>\n",
       "      <td>31.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,544</td>\n",
       "      <td>23.1%</td>\n",
       "      <td>984</td>\n",
       "      <td>14.7%</td>\n",
       "      <td>785</td>\n",
       "      <td>11.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1944</td>\n",
       "      <td>8,328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>865</td>\n",
       "      <td>10.4%</td>\n",
       "      <td>2,329</td>\n",
       "      <td>28.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,104</td>\n",
       "      <td>25.3%</td>\n",
       "      <td>1,560</td>\n",
       "      <td>18.7%</td>\n",
       "      <td>1,470</td>\n",
       "      <td>17.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1945</td>\n",
       "      <td>9,067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,258</td>\n",
       "      <td>13.9%</td>\n",
       "      <td>2,791</td>\n",
       "      <td>30.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,421</td>\n",
       "      <td>26.7%</td>\n",
       "      <td>1,506</td>\n",
       "      <td>16.6%</td>\n",
       "      <td>1,091</td>\n",
       "      <td>12.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1946</td>\n",
       "      <td>6,681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,049</td>\n",
       "      <td>15.7%</td>\n",
       "      <td>2,512</td>\n",
       "      <td>37.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,710</td>\n",
       "      <td>25.6%</td>\n",
       "      <td>869</td>\n",
       "      <td>13.0%</td>\n",
       "      <td>541</td>\n",
       "      <td>8.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1947</td>\n",
       "      <td>2,932</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2%</td>\n",
       "      <td>305</td>\n",
       "      <td>10.4%</td>\n",
       "      <td>1,536</td>\n",
       "      <td>52.4%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>695</td>\n",
       "      <td>23.7%</td>\n",
       "      <td>252</td>\n",
       "      <td>8.6%</td>\n",
       "      <td>138</td>\n",
       "      <td>4.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1948</td>\n",
       "      <td>2,022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1949</td>\n",
       "      <td>2,280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.9%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1950</td>\n",
       "      <td>2,262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1951</td>\n",
       "      <td>6,250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1952</td>\n",
       "      <td>8,784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1953</td>\n",
       "      <td>6,529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1954</td>\n",
       "      <td>5,708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1955</td>\n",
       "      <td>6,050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1956</td>\n",
       "      <td>6,989</td>\n",
       "      <td>401</td>\n",
       "      <td>5.7%</td>\n",
       "      <td>3,994</td>\n",
       "      <td>57.1%</td>\n",
       "      <td>1,843</td>\n",
       "      <td>26.4%</td>\n",
       "      <td>153.000</td>\n",
       "      <td>2.19%</td>\n",
       "      <td>249</td>\n",
       "      <td>3.56%</td>\n",
       "      <td>300</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>39</td>\n",
       "      <td>0.56%</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1957</td>\n",
       "      <td>6,943</td>\n",
       "      <td>366</td>\n",
       "      <td>5.3%</td>\n",
       "      <td>4,097</td>\n",
       "      <td>59.0%</td>\n",
       "      <td>1,883</td>\n",
       "      <td>27.1%</td>\n",
       "      <td>263.000</td>\n",
       "      <td>3.79%</td>\n",
       "      <td>115</td>\n",
       "      <td>1.66%</td>\n",
       "      <td>174</td>\n",
       "      <td>2.51%</td>\n",
       "      <td>37</td>\n",
       "      <td>0.53%</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1958</td>\n",
       "      <td>6,449</td>\n",
       "      <td>231</td>\n",
       "      <td>3.6%</td>\n",
       "      <td>3,998</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>1,847</td>\n",
       "      <td>28.6%</td>\n",
       "      <td>190.000</td>\n",
       "      <td>2.95%</td>\n",
       "      <td>72</td>\n",
       "      <td>1.12%</td>\n",
       "      <td>77</td>\n",
       "      <td>1.19%</td>\n",
       "      <td>29</td>\n",
       "      <td>0.45%</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1959</td>\n",
       "      <td>6,728</td>\n",
       "      <td>191</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>4,445</td>\n",
       "      <td>66.1%</td>\n",
       "      <td>1,776</td>\n",
       "      <td>26.4%</td>\n",
       "      <td>170.000</td>\n",
       "      <td>2.53%</td>\n",
       "      <td>55</td>\n",
       "      <td>0.82%</td>\n",
       "      <td>77</td>\n",
       "      <td>1.14%</td>\n",
       "      <td>12</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1960</td>\n",
       "      <td>7,058</td>\n",
       "      <td>199</td>\n",
       "      <td>2.8%</td>\n",
       "      <td>4,660</td>\n",
       "      <td>66.0%</td>\n",
       "      <td>1,773</td>\n",
       "      <td>25.1%</td>\n",
       "      <td>199.000</td>\n",
       "      <td>2.82%</td>\n",
       "      <td>57</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>156</td>\n",
       "      <td>2.21%</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1961</td>\n",
       "      <td>7,439</td>\n",
       "      <td>260</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>5,149</td>\n",
       "      <td>69.2%</td>\n",
       "      <td>1,590</td>\n",
       "      <td>21.4%</td>\n",
       "      <td>202.000</td>\n",
       "      <td>2.72%</td>\n",
       "      <td>45</td>\n",
       "      <td>0.60%</td>\n",
       "      <td>145</td>\n",
       "      <td>1.95%</td>\n",
       "      <td>45</td>\n",
       "      <td>0.60%</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1962</td>\n",
       "      <td>7,400</td>\n",
       "      <td>243</td>\n",
       "      <td>3.3%</td>\n",
       "      <td>5,135</td>\n",
       "      <td>69.4%</td>\n",
       "      <td>1,620</td>\n",
       "      <td>21.9%</td>\n",
       "      <td>192.000</td>\n",
       "      <td>2.59%</td>\n",
       "      <td>55</td>\n",
       "      <td>0.74%</td>\n",
       "      <td>125</td>\n",
       "      <td>1.69%</td>\n",
       "      <td>28</td>\n",
       "      <td>0.38%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.6%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1963</td>\n",
       "      <td>8,312</td>\n",
       "      <td>306</td>\n",
       "      <td>3.7%</td>\n",
       "      <td>6,040</td>\n",
       "      <td>72.7%</td>\n",
       "      <td>1,616</td>\n",
       "      <td>19.4%</td>\n",
       "      <td>170.000</td>\n",
       "      <td>2.05%</td>\n",
       "      <td>37</td>\n",
       "      <td>0.45%</td>\n",
       "      <td>120</td>\n",
       "      <td>1.44%</td>\n",
       "      <td>21</td>\n",
       "      <td>0.25%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.02%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1964</td>\n",
       "      <td>10,053</td>\n",
       "      <td>439</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>7,215</td>\n",
       "      <td>71.8%</td>\n",
       "      <td>1,756</td>\n",
       "      <td>17.5%</td>\n",
       "      <td>204.000</td>\n",
       "      <td>2.03%</td>\n",
       "      <td>38</td>\n",
       "      <td>0.38%</td>\n",
       "      <td>184</td>\n",
       "      <td>1.83%</td>\n",
       "      <td>214</td>\n",
       "      <td>2.13%</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.7%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1965</td>\n",
       "      <td>10,295</td>\n",
       "      <td>611</td>\n",
       "      <td>5.9%</td>\n",
       "      <td>7,577</td>\n",
       "      <td>73.6%</td>\n",
       "      <td>1,593</td>\n",
       "      <td>15.5%</td>\n",
       "      <td>188.000</td>\n",
       "      <td>1.83%</td>\n",
       "      <td>57</td>\n",
       "      <td>0.55%</td>\n",
       "      <td>195</td>\n",
       "      <td>1.89%</td>\n",
       "      <td>73</td>\n",
       "      <td>0.71%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.1%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1966</td>\n",
       "      <td>12,037</td>\n",
       "      <td>770</td>\n",
       "      <td>6.4%</td>\n",
       "      <td>9,158</td>\n",
       "      <td>76.1%</td>\n",
       "      <td>1,742</td>\n",
       "      <td>14.5%</td>\n",
       "      <td>125.000</td>\n",
       "      <td>1.04%</td>\n",
       "      <td>50</td>\n",
       "      <td>0.42%</td>\n",
       "      <td>150</td>\n",
       "      <td>1.25%</td>\n",
       "      <td>42</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.8%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1967</td>\n",
       "      <td>12,729</td>\n",
       "      <td>919</td>\n",
       "      <td>7.2%</td>\n",
       "      <td>9,774</td>\n",
       "      <td>76.8%</td>\n",
       "      <td>1,758</td>\n",
       "      <td>13.8%</td>\n",
       "      <td>93.000</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>35</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>125</td>\n",
       "      <td>0.98%</td>\n",
       "      <td>25</td>\n",
       "      <td>0.20%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.7%</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9%</td>\n",
       "      <td>403</td>\n",
       "      <td>35.4%</td>\n",
       "      <td>706</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>19</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1968</td>\n",
       "      <td>13,081</td>\n",
       "      <td>889</td>\n",
       "      <td>6.8%</td>\n",
       "      <td>10,181</td>\n",
       "      <td>77.8%</td>\n",
       "      <td>1,717</td>\n",
       "      <td>13.1%</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>39</td>\n",
       "      <td>0.30%</td>\n",
       "      <td>165</td>\n",
       "      <td>1.26%</td>\n",
       "      <td>15</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.3%</td>\n",
       "      <td>17</td>\n",
       "      <td>0.7%</td>\n",
       "      <td>776</td>\n",
       "      <td>33.8%</td>\n",
       "      <td>1,467</td>\n",
       "      <td>64.0%</td>\n",
       "      <td>31</td>\n",
       "      <td>1.35%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1969</td>\n",
       "      <td>13,385</td>\n",
       "      <td>911</td>\n",
       "      <td>6.8%</td>\n",
       "      <td>10,382</td>\n",
       "      <td>77.6%</td>\n",
       "      <td>1,727</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0.56%</td>\n",
       "      <td>43</td>\n",
       "      <td>0.32%</td>\n",
       "      <td>222</td>\n",
       "      <td>1.66%</td>\n",
       "      <td>25</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.9%</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>949</td>\n",
       "      <td>37.3%</td>\n",
       "      <td>1,542</td>\n",
       "      <td>60.6%</td>\n",
       "      <td>24</td>\n",
       "      <td>0.94%</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1970</td>\n",
       "      <td>13,927</td>\n",
       "      <td>949</td>\n",
       "      <td>6.8%</td>\n",
       "      <td>11,082</td>\n",
       "      <td>79.6%</td>\n",
       "      <td>1,649</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>54.000</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>33</td>\n",
       "      <td>0.24%</td>\n",
       "      <td>150</td>\n",
       "      <td>1.08%</td>\n",
       "      <td>10</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.9%</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>1,154</td>\n",
       "      <td>32.7%</td>\n",
       "      <td>2,316</td>\n",
       "      <td>65.6%</td>\n",
       "      <td>24</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.06%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1971*</td>\n",
       "      <td>13,955</td>\n",
       "      <td>847</td>\n",
       "      <td>6.1%</td>\n",
       "      <td>11,173</td>\n",
       "      <td>80.1%</td>\n",
       "      <td>1,709</td>\n",
       "      <td>12.2%</td>\n",
       "      <td>58.000</td>\n",
       "      <td>0.42%</td>\n",
       "      <td>21</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>138</td>\n",
       "      <td>0.99%</td>\n",
       "      <td>8</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.3%</td>\n",
       "      <td>(FIGURES NOT AVAILABLE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1972*</td>\n",
       "      <td>13,565</td>\n",
       "      <td>801</td>\n",
       "      <td>5.9%</td>\n",
       "      <td>10,951</td>\n",
       "      <td>80.7%</td>\n",
       "      <td>1,683</td>\n",
       "      <td>12.4%</td>\n",
       "      <td>31.000</td>\n",
       "      <td>0.23%</td>\n",
       "      <td>11</td>\n",
       "      <td>0.08%</td>\n",
       "      <td>81</td>\n",
       "      <td>0.60%</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.1%</td>\n",
       "      <td>31</td>\n",
       "      <td>0.5%</td>\n",
       "      <td>1,612</td>\n",
       "      <td>26.2%</td>\n",
       "      <td>4,365</td>\n",
       "      <td>71.0%</td>\n",
       "      <td>132</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>12.000</td>\n",
       "      <td>0.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1973</td>\n",
       "      <td>12,142</td>\n",
       "      <td>745</td>\n",
       "      <td>6.1%</td>\n",
       "      <td>9,776</td>\n",
       "      <td>80.5%</td>\n",
       "      <td>1,489</td>\n",
       "      <td>12.3%</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.21%</td>\n",
       "      <td>15</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>83</td>\n",
       "      <td>0.68%</td>\n",
       "      <td>8</td>\n",
       "      <td>0.07%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.6%</td>\n",
       "      <td>52</td>\n",
       "      <td>0.7%</td>\n",
       "      <td>1,984</td>\n",
       "      <td>27.4%</td>\n",
       "      <td>4,907</td>\n",
       "      <td>67.9%</td>\n",
       "      <td>255</td>\n",
       "      <td>3.5%</td>\n",
       "      <td>33.000</td>\n",
       "      <td>0.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1974</td>\n",
       "      <td>12,403</td>\n",
       "      <td>779</td>\n",
       "      <td>6.3%</td>\n",
       "      <td>9,849</td>\n",
       "      <td>79.4%</td>\n",
       "      <td>1,444</td>\n",
       "      <td>11.6%</td>\n",
       "      <td>42.000</td>\n",
       "      <td>0.34%</td>\n",
       "      <td>38</td>\n",
       "      <td>0.31%</td>\n",
       "      <td>237</td>\n",
       "      <td>1.91%</td>\n",
       "      <td>14</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.3%</td>\n",
       "      <td>71</td>\n",
       "      <td>0.8%</td>\n",
       "      <td>2,175</td>\n",
       "      <td>25.1%</td>\n",
       "      <td>5,829</td>\n",
       "      <td>67.3%</td>\n",
       "      <td>516</td>\n",
       "      <td>6.0%</td>\n",
       "      <td>75.000</td>\n",
       "      <td>0.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1975</td>\n",
       "      <td>10,266</td>\n",
       "      <td>528</td>\n",
       "      <td>5.1%</td>\n",
       "      <td>7,936</td>\n",
       "      <td>77.3%</td>\n",
       "      <td>1,321</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>72.000</td>\n",
       "      <td>0.70%</td>\n",
       "      <td>39</td>\n",
       "      <td>0.38%</td>\n",
       "      <td>317</td>\n",
       "      <td>3.09%</td>\n",
       "      <td>52</td>\n",
       "      <td>0.51%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.4%</td>\n",
       "      <td>151</td>\n",
       "      <td>1.7%</td>\n",
       "      <td>2,809</td>\n",
       "      <td>31.1%</td>\n",
       "      <td>5,746</td>\n",
       "      <td>63.6%</td>\n",
       "      <td>296</td>\n",
       "      <td>3.3%</td>\n",
       "      <td>27.000</td>\n",
       "      <td>0.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1976</td>\n",
       "      <td>13,909</td>\n",
       "      <td>1,369</td>\n",
       "      <td>9.8%</td>\n",
       "      <td>11,062</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>895</td>\n",
       "      <td>6.4%</td>\n",
       "      <td>58.000</td>\n",
       "      <td>0.42%</td>\n",
       "      <td>85</td>\n",
       "      <td>0.61%</td>\n",
       "      <td>365</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>74</td>\n",
       "      <td>0.53%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.1%</td>\n",
       "      <td>227</td>\n",
       "      <td>2.1%</td>\n",
       "      <td>2,295</td>\n",
       "      <td>20.8%</td>\n",
       "      <td>6,900</td>\n",
       "      <td>62.4%</td>\n",
       "      <td>1,426</td>\n",
       "      <td>12.9%</td>\n",
       "      <td>210.000</td>\n",
       "      <td>1.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1977</td>\n",
       "      <td>13,990</td>\n",
       "      <td>1,194</td>\n",
       "      <td>8.5%</td>\n",
       "      <td>11,661</td>\n",
       "      <td>83.4%</td>\n",
       "      <td>722</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>86</td>\n",
       "      <td>0.61%</td>\n",
       "      <td>267</td>\n",
       "      <td>1.91%</td>\n",
       "      <td>22</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.9%</td>\n",
       "      <td>335</td>\n",
       "      <td>2.4%</td>\n",
       "      <td>4,306</td>\n",
       "      <td>30.9%</td>\n",
       "      <td>7,982</td>\n",
       "      <td>57.3%</td>\n",
       "      <td>1,156</td>\n",
       "      <td>8.3%</td>\n",
       "      <td>155.000</td>\n",
       "      <td>1.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1978</td>\n",
       "      <td>13,551</td>\n",
       "      <td>826</td>\n",
       "      <td>6.1%</td>\n",
       "      <td>11,854</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>643</td>\n",
       "      <td>4.7%</td>\n",
       "      <td>28.000</td>\n",
       "      <td>0.21%</td>\n",
       "      <td>47</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>141</td>\n",
       "      <td>1.04%</td>\n",
       "      <td>12</td>\n",
       "      <td>0.09%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.5%</td>\n",
       "      <td>294</td>\n",
       "      <td>2.2%</td>\n",
       "      <td>4,120</td>\n",
       "      <td>30.4%</td>\n",
       "      <td>7,906</td>\n",
       "      <td>58.3%</td>\n",
       "      <td>1,103</td>\n",
       "      <td>8.1%</td>\n",
       "      <td>129.000</td>\n",
       "      <td>0.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1979</td>\n",
       "      <td>11,986</td>\n",
       "      <td>730</td>\n",
       "      <td>6.1%</td>\n",
       "      <td>10,671</td>\n",
       "      <td>89.0%</td>\n",
       "      <td>490</td>\n",
       "      <td>4.1%</td>\n",
       "      <td>19.000</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>18</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>52</td>\n",
       "      <td>0.43%</td>\n",
       "      <td>5</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.01%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.6%</td>\n",
       "      <td>214</td>\n",
       "      <td>1.8%</td>\n",
       "      <td>3,470</td>\n",
       "      <td>29.0%</td>\n",
       "      <td>7,044</td>\n",
       "      <td>58.8%</td>\n",
       "      <td>1,115</td>\n",
       "      <td>9.3%</td>\n",
       "      <td>142.000</td>\n",
       "      <td>1.18%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR POUNDS GRADED  PRIME     %  CHOICE    %.1 SELECT    %.2  STNDRD  \\\n",
       "0    1930            69    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "1    1931           159    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "2    1932           208    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "3    1933           238    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "4    1934           262    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "5    1935           268    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "6    1936           450    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "7    1937           408    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "8    1938           598     27  4.5%     283  47.3%    187  31.3%     NaN   \n",
       "9    1939           509     10  2.0%     232  45.6%    176  34.6%     NaN   \n",
       "10   1940           579     12  2.1%     230  39.7%    234  40.4%     NaN   \n",
       "11   1941           789     13  1.6%     308  39.0%    344  43.6%     NaN   \n",
       "12   1942         1,478    NaN   NaN     439  29.7%    560  37.9%     NaN   \n",
       "13   1943         6,691    NaN   NaN   1,297  19.4%  2,081  31.1%     NaN   \n",
       "14   1944         8,328    NaN   NaN     865  10.4%  2,329  28.0%     NaN   \n",
       "15   1945         9,067    NaN   NaN   1,258  13.9%  2,791  30.8%     NaN   \n",
       "16   1946         6,681    NaN   NaN   1,049  15.7%  2,512  37.6%     NaN   \n",
       "17   1947         2,932      6  0.2%     305  10.4%  1,536  52.4%     NaN   \n",
       "18   1948         2,022    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "19   1949         2,280    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "20   1950         2,262    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "21   1951         6,250    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "22   1952         8,784    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "23   1953         6,529    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "24   1954         5,708    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "25   1955         6,050    NaN   NaN     NaN    NaN    NaN    NaN     NaN   \n",
       "26   1956         6,989    401  5.7%   3,994  57.1%  1,843  26.4% 153.000   \n",
       "27   1957         6,943    366  5.3%   4,097  59.0%  1,883  27.1% 263.000   \n",
       "28   1958         6,449    231  3.6%   3,998  62.0%  1,847  28.6% 190.000   \n",
       "29   1959         6,728    191  2.8%   4,445  66.1%  1,776  26.4% 170.000   \n",
       "30   1960         7,058    199  2.8%   4,660  66.0%  1,773  25.1% 199.000   \n",
       "31   1961         7,439    260  3.5%   5,149  69.2%  1,590  21.4% 202.000   \n",
       "32   1962         7,400    243  3.3%   5,135  69.4%  1,620  21.9% 192.000   \n",
       "33   1963         8,312    306  3.7%   6,040  72.7%  1,616  19.4% 170.000   \n",
       "34   1964        10,053    439  4.4%   7,215  71.8%  1,756  17.5% 204.000   \n",
       "35   1965        10,295    611  5.9%   7,577  73.6%  1,593  15.5% 188.000   \n",
       "36   1966        12,037    770  6.4%   9,158  76.1%  1,742  14.5% 125.000   \n",
       "37   1967        12,729    919  7.2%   9,774  76.8%  1,758  13.8%  93.000   \n",
       "38   1968        13,081    889  6.8%  10,181  77.8%  1,717  13.1%  75.000   \n",
       "39   1969        13,385    911  6.8%  10,382  77.6%  1,727  12.9%  75.000   \n",
       "40   1970        13,927    949  6.8%  11,082  79.6%  1,649  11.8%  54.000   \n",
       "41  1971*        13,955    847  6.1%  11,173  80.1%  1,709  12.2%  58.000   \n",
       "42  1972*        13,565    801  5.9%  10,951  80.7%  1,683  12.4%  31.000   \n",
       "43   1973        12,142    745  6.1%   9,776  80.5%  1,489  12.3%  25.000   \n",
       "44   1974        12,403    779  6.3%   9,849  79.4%  1,444  11.6%  42.000   \n",
       "45   1975        10,266    528  5.1%   7,936  77.3%  1,321  12.9%  72.000   \n",
       "46   1976        13,909  1,369  9.8%  11,062  79.5%    895   6.4%  58.000   \n",
       "47   1977        13,990  1,194  8.5%  11,661  83.4%    722   5.2%  38.000   \n",
       "48   1978        13,551    826  6.1%  11,854  87.5%    643   4.7%  28.000   \n",
       "49   1979        11,986    730  6.1%  10,671  89.0%    490   4.1%  19.000   \n",
       "\n",
       "      %.3 COMRCL    %.4 UTILITY    %.5 CUTTER    %.6  CANNER    %.7  S/H  \\\n",
       "0     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "1     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "2     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "3     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "4     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "5     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "6     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "7     NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "8     NaN     54   9.0%      34   5.7%     11   1.8%   2.000  0.33%  NaN   \n",
       "9     NaN     55  10.8%      29   5.7%      6   1.2%   1.000  0.20%  NaN   \n",
       "10    NaN     69  11.9%      25   4.3%      7   1.2%   2.000  0.35%  NaN   \n",
       "11    NaN     86  10.9%      26   3.3%      9   1.1%   3.000  0.38%  NaN   \n",
       "12    NaN    284  19.2%     173  11.7%     15   1.0%   7.000  0.47%  NaN   \n",
       "13    NaN  1,544  23.1%     984  14.7%    785  11.7%     NaN    NaN  NaN   \n",
       "14    NaN  2,104  25.3%   1,560  18.7%  1,470  17.7%     NaN    NaN  NaN   \n",
       "15    NaN  2,421  26.7%   1,506  16.6%  1,091  12.0%     NaN    NaN  NaN   \n",
       "16    NaN  1,710  25.6%     869  13.0%    541   8.1%     NaN    NaN  NaN   \n",
       "17    NaN    695  23.7%     252   8.6%    138   4.7%     NaN    NaN  NaN   \n",
       "18    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "19    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "20    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "21    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "22    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "23    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "24    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "25    NaN    NaN    NaN     NaN    NaN    NaN    NaN     NaN    NaN  NaN   \n",
       "26  2.19%    249  3.56%     300  4.29%     39  0.56%  10.000  0.14%  NaN   \n",
       "27  3.79%    115  1.66%     174  2.51%     37  0.53%   8.000  0.12%  NaN   \n",
       "28  2.95%     72  1.12%      77  1.19%     29  0.45%   5.000  0.08%  NaN   \n",
       "29  2.53%     55  0.82%      77  1.14%     12  0.18%   2.000  0.03%  NaN   \n",
       "30  2.82%     57  0.81%     156  2.21%     12  0.17%   2.000  0.03%  NaN   \n",
       "31  2.72%     45  0.60%     145  1.95%     45  0.60%   3.000  0.04%  NaN   \n",
       "32  2.59%     55  0.74%     125  1.69%     28  0.38%   2.000  0.03%  NaN   \n",
       "33  2.05%     37  0.45%     120  1.44%     21  0.25%   2.000  0.02%  NaN   \n",
       "34  2.03%     38  0.38%     184  1.83%    214  2.13%   3.000  0.03%  NaN   \n",
       "35  1.83%     57  0.55%     195  1.89%     73  0.71%   1.000  0.01%  NaN   \n",
       "36  1.04%     50  0.42%     150  1.25%     42  0.35%     NaN    NaN  NaN   \n",
       "37  0.73%     35  0.27%     125  0.98%     25  0.20%     NaN    NaN  NaN   \n",
       "38  0.57%     39  0.30%     165  1.26%     15  0.11%     NaN    NaN  NaN   \n",
       "39  0.56%     43  0.32%     222  1.66%     25  0.19%     NaN    NaN  NaN   \n",
       "40  0.39%     33  0.24%     150  1.08%     10  0.07%     NaN    NaN  NaN   \n",
       "41  0.42%     21  0.15%     138  0.99%      8  0.06%   1.000  0.01%  NaN   \n",
       "42  0.23%     11  0.08%      81  0.60%      7  0.05%     NaN    NaN  NaN   \n",
       "43  0.21%     15  0.12%      83  0.68%      8  0.07%   1.000  0.01%  NaN   \n",
       "44  0.34%     38  0.31%     237  1.91%     14  0.11%     NaN    NaN  NaN   \n",
       "45  0.70%     39  0.38%     317  3.09%     52  0.51%   1.000  0.01%  NaN   \n",
       "46  0.42%     85  0.61%     365  2.62%     74  0.53%   1.000  0.01%  NaN   \n",
       "47  0.27%     86  0.61%     267  1.91%     22  0.16%     NaN    NaN  NaN   \n",
       "48  0.21%     47  0.35%     141  1.04%     12  0.09%     NaN    NaN  NaN   \n",
       "49  0.16%     18  0.15%      52  0.43%      5  0.04%   1.000  0.01%  NaN   \n",
       "\n",
       "   %  of FEDERAL  SLAUGHTER\\t BEEF                            Y1   %.8     Y2  \\\n",
       "0                             1.2%                           NaN   NaN    NaN   \n",
       "1                             2.7%                           NaN   NaN    NaN   \n",
       "2                             3.8%                           NaN   NaN    NaN   \n",
       "3                             3.9%                           NaN   NaN    NaN   \n",
       "4                             3.3%                           NaN   NaN    NaN   \n",
       "5                             4.2%                           NaN   NaN    NaN   \n",
       "6                             6.3%                           NaN   NaN    NaN   \n",
       "7                             6.2%                           NaN   NaN    NaN   \n",
       "8                             9.0%                           NaN   NaN    NaN   \n",
       "9                             7.5%                           NaN   NaN    NaN   \n",
       "10                            8.3%                           NaN   NaN    NaN   \n",
       "11                           10.1%                           NaN   NaN    NaN   \n",
       "12                           17.3%                           NaN   NaN    NaN   \n",
       "13                           80.8%                           NaN   NaN    NaN   \n",
       "14                           94.9%                           NaN   NaN    NaN   \n",
       "15                           92.4%                           NaN   NaN    NaN   \n",
       "16                           76.0%                           NaN   NaN    NaN   \n",
       "17                           29.0%                           NaN   NaN    NaN   \n",
       "18                           23.1%                           NaN   NaN    NaN   \n",
       "19                           24.9%                           NaN   NaN    NaN   \n",
       "20                           24.5%                           NaN   NaN    NaN   \n",
       "21                           73.1%                           NaN   NaN    NaN   \n",
       "22                           94.1%                           NaN   NaN    NaN   \n",
       "23                           54.2%                           NaN   NaN    NaN   \n",
       "24                           45.3%                           NaN   NaN    NaN   \n",
       "25                           45.8%                           NaN   NaN    NaN   \n",
       "26                           49.6%                           NaN   NaN    NaN   \n",
       "27                           50.1%                           NaN   NaN    NaN   \n",
       "28                           49.6%                           NaN   NaN    NaN   \n",
       "29                           50.8%                           NaN   NaN    NaN   \n",
       "30                           49.1%                           NaN   NaN    NaN   \n",
       "31                           49.8%                           NaN   NaN    NaN   \n",
       "32                           49.6%                           NaN   NaN    NaN   \n",
       "33                           51.8%                           NaN   NaN    NaN   \n",
       "34                           55.7%                           NaN   NaN    NaN   \n",
       "35                           58.1%                           NaN   NaN    NaN   \n",
       "36                           61.8%                           NaN   NaN    NaN   \n",
       "37                           63.7%                            10  0.9%    403   \n",
       "38                           63.3%                            17  0.7%    776   \n",
       "39                           63.9%                            26  1.0%    949   \n",
       "40                           64.9%                            35  1.0%  1,154   \n",
       "41                           64.3%       (FIGURES NOT AVAILABLE)   NaN    NaN   \n",
       "42                           61.1%                            31  0.5%  1,612   \n",
       "43                           57.6%                            52  0.7%  1,984   \n",
       "44                           54.3%                            71  0.8%  2,175   \n",
       "45                           43.4%                           151  1.7%  2,809   \n",
       "46                           54.1%                           227  2.1%  2,295   \n",
       "47                           55.9%                           335  2.4%  4,306   \n",
       "48                           59.5%                           294  2.2%  4,120   \n",
       "49                           57.6%                           214  1.8%  3,470   \n",
       "\n",
       "      %.9     Y3   %.10     Y4   %.11      Y5   %.12  \n",
       "0     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "1     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "2     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "3     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "4     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "5     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "6     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "7     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "8     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "9     NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "10    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "11    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "12    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "13    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "14    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "15    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "16    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "17    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "18    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "19    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "20    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "21    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "22    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "23    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "24    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "25    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "26    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "27    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "28    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "29    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "30    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "31    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "32    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "33    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "34    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "35    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "36    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "37  35.4%    706  62.0%     19  1.67%   1.000  0.09%  \n",
       "38  33.8%  1,467  64.0%     31  1.35%   2.000  0.09%  \n",
       "39  37.3%  1,542  60.6%     24  0.94%   3.000  0.12%  \n",
       "40  32.7%  2,316  65.6%     24  0.68%   2.000  0.06%  \n",
       "41    NaN    NaN    NaN    NaN    NaN     NaN    NaN  \n",
       "42  26.2%  4,365  71.0%    132   2.1%  12.000  0.20%  \n",
       "43  27.4%  4,907  67.9%    255   3.5%  33.000  0.46%  \n",
       "44  25.1%  5,829  67.3%    516   6.0%  75.000  0.87%  \n",
       "45  31.1%  5,746  63.6%    296   3.3%  27.000  0.30%  \n",
       "46  20.8%  6,900  62.4%  1,426  12.9% 210.000  1.90%  \n",
       "47  30.9%  7,982  57.3%  1,156   8.3% 155.000  1.11%  \n",
       "48  30.4%  7,906  58.3%  1,103   8.1% 129.000  0.95%  \n",
       "49  29.0%  7,044  58.8%  1,115   9.3% 142.000  1.18%  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Netejant les dades\n",
    "print(type(dataset))\n",
    "#dataset[np.isnan(dataset)] = 'BORRAR'\n",
    "#dataset = dataset.drop(dataset.query('YEAR==str(NaN)'))\n",
    "\n",
    "newDataset = dataset.dropna(subset=['YEAR'], how=\"all\")\n",
    "newDataset = newDataset.iloc[:-6] #Borrar 6 lineas final\n",
    "newDataset = newDataset.reset_index(drop=True) #Reorganizar indices\n",
    "\n",
    "print(type(dataset['YEAR'][11]))\n",
    "newDataset[0:50]\n",
    "\n",
    "#Nombre de valor\n",
    "print(\"Per comptar el nombre de valors no existents:\")\n",
    "print(newDataset.isnull().sum())\n",
    "newDataset[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esborrar columnes de CANNER,%.7,S/H  <50% drop   >50% fill with  mean\n",
    "to_drop = ['CANNER','%.7','S/H']\n",
    "newDataset.drop(columns=to_drop, inplace=True)\n",
    "newDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Per visualitzar les primeres 5 mostres de la BBDD:\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDataset[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Per veure estadístiques dels atributs numèrics de la BBDD:\")\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrem atribut 0\n",
    "plt.figure()\n",
    "\n",
    "ax = plt.scatter(x[:,0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histograma de l'atribut 0\")\n",
    "plt.xlabel(\"Attribute Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "hist = plt.hist(x[:,0], bins=11, range=[np.min(x[:,0]), np.max(x[:,0])], histtype=\"bar\", rwidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També podem estudiar la correlació entre els diferents atributs per tal de saber si estan correlacionats entre ells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Mirem la correlació entre els atributs d'entrada per entendre millor les dades\n",
    "correlacio = dataset.corr()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També podem utilitzar la funció pairplot per tal de veure els atributs que estan relacionats entre si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirem la relació entre atributs utilitzant la funció pairplot\n",
    "relacio = sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Així doncs ara podreu respondre a les següents preguntes:\n",
    "\n",
    "1. Quin és el tipus de cada atribut? \n",
    "2. Quins atributs tenen una distribució Guassiana?\n",
    "3. Quin és l'atribut objectiu? Per què?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (B): Primeres regressions\n",
    "\n",
    "Per a aquest primer apartat es calcularà l'error quadràtic mitjà només del regressor per a cada un dels atributs de la base de dades, determinant aquell atribut pel qual l'error quadràtic mitjà (entre el valor predit i el real, per a cada mostra) és més baix. \n",
    "\n",
    "A continuació se us dona una funció auxiliar per a calcular l'error quadràtic mitjà:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mean_squeared_error(y1, y2):\n",
    "    # comprovem que y1 i y2 tenen la mateixa mida\n",
    "    assert(len(y1) == len(y2))\n",
    "    mse = 0\n",
    "    for i in range(len(y1)):\n",
    "        mse += (y1[i] - y2[i])**2\n",
    "    return mse / len(y1)\n",
    "\n",
    "mean_squeared_error([1,2,3,4], [1,2,1,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per a agilitzar els càlculs es recomana utilitzar la llibreria numpy. Aquesta llibreria ens permet processar vectors sencers a la vegada de manera eficient i en paral·lel. Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importem la llibreria\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "vector1 = np.array([1,2,3,4]) # convertim llista de python a numpy array\n",
    "vector2 = np.array([1,2,1,4]) \n",
    "\n",
    "# podem sumar dos vectors element a element\n",
    "print(\"Suma vector1 + vector2 \", vector1 + vector2)\n",
    "\n",
    "# podem sumar tots els valors d'un vector\n",
    "print(\"Suma valors vector1 \", vector1.sum())\n",
    "\n",
    "# calculem la mitjana\n",
    "print(\"Mitjana vector1\", vector1.mean())\n",
    "\n",
    "# utilitzem un vector com a índex de l'altre\n",
    "# vector3 = vector1  # necesitem fer una copia del vector per no modificar el original\n",
    "vector3 = vector1.copy()\n",
    "vector3[vector2 == 1] = 5\n",
    "print(\"Vector1 amb un 5 on el Vector2 te 1s \", vector3)\n",
    "\n",
    "# es pot utilitzar numpy per a calcular el mse\n",
    "def mse(v1, v2):\n",
    "    return ((v1 - v2)**2).mean()\n",
    "\n",
    "print(\"MSE: \", mse(vector1, vector2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per a la regressió podeu utilitzar la llibreria sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(x, y):\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = LinearRegression()\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, si la funció `fit` del regressor logístic dónes l'error: `ValueError: Unknown label type: 'unknown'`, caldria afegir a la definició de l'atribut a trobar $y$ la crida a la funció `.astype('int')` per tal de obligar a que les dades siguin de tipus sencer, deixant el codi com segueix:\n",
    "\n",
    "`y = data[:,2].astype('int')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació, es modificaran tots els atributs mitjançant **procediments de normalització (normal, estàndard)**, i s'avaluarà el rendiment del regressor après. Per a això, caldrà analitzar la mitja i variança de cada variable per totes les mostres, per identificar aquells valors que tenen una distribució normal, els preferits per fer regressió, i descartar altres atributs que no són representatius per fer la regressió, i que afegeixen soroll al model. \n",
    "\n",
    "Pel que fa a l'error resultant de la regressió, recordeu que es calcula fent la diferència entre el valor predit i el real al quadrat: així doncs, si les dades tenen valors grans (tipus 10^3), l'error al quadrat podria acabar sent 10^6. Per això és important normalitzar abans (escalar les dades a un rang més petit).\n",
    "\n",
    "<img src=\"images/standarization.png\">\n",
    "\n",
    "Podeu estandarditzar les dades amb les funcions mean i std de numpy i mostrar l'hisotgrama de nou. Recuperant l'exemple de l'apartat anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(x_train):\n",
    "    mean = x_train.mean(0)\n",
    "    std = x_train.std(0)\n",
    "    x_t = x_train - mean[None, :]\n",
    "    x_t /= std[None, :]\n",
    "    return x_t\n",
    "\n",
    "x_t = standarize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ja podeu comprovar la diferència entre entrenar amb els atributs estandaritzats i si aquells que tenen una distribució més semblant a la normal donen millors resultats. \n",
    "Finalment, s'aprendrà un model regressor tenint en compte tots aquells atributs que tenen una millor distribució de valors (lineal, això és, l'histograma de valors té forma de gaussiana), i es calcularà l'error assolit en la predicció. \n",
    "\n",
    "Recordeu que el valor sobre el que heu de fer la regressió queda al vostre criteri: **heu d'explicar a la memòria quin atribut heu fet servir, no hi ha una decisió única correcta, cal que doneu raons de per què heu triat l'atribut que hàgiu triat.**\n",
    "\n",
    "Així per exemple pode mirar:\n",
    "\n",
    "* Que l'objectiu de la regressió sigui un valor ordinal (1 > 2 > 3). Si no n'hi ha cap, explicar-ho a la memòria.\n",
    "\n",
    "* Que sigui útil en alguna aplicació real (per exemple predir si plourà és més interessant que predir el color dels núvols).\n",
    "\n",
    "* Que tingui certa variació (un atribut que és sempre 0, no té gaire interès)\n",
    "\n",
    "I en definitiva explicar el criteri a seguir, tant amb paraules com amb gràfiques (per exemple histograma), o estadístiques (per exemple la variança dels atributs) si escau.\n",
    "\n",
    "Un cop escollit l'atribut objectiu, caldrà justificar si l'error obtingut és, en proporció, menor que tenint en compte únicament el millor atribut identificat al primer punt. \n",
    "\n",
    "Podeu utilitzar les funcions hist de matplotlib per a calcular els histogrames. Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histograma de l'atribut 0\")\n",
    "plt.xlabel(\"Attribute Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "hist = plt.hist(x_t[:,0], bins=11, range=[np.min(x_t[:,0]), np.max(x_t[:,0])], histtype=\"bar\", rwidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o utilitzar les funcions de visualitzación del propi pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['attr2'],1).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara que hem carregat les dades podem entrenar un regressor lineal per a aproximar la funció que les genera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Extraiem el primer atribut de x i canviem la mida a #exemples, #dimensions de l'atribut.\n",
    "# En el vostre cas, haureu de triar un atribut com a y, i utilitzar la resta com a x.\n",
    "atribut1 = x[:,0].reshape(x.shape[0], 1) \n",
    "regr = regression(atribut1, y) \n",
    "predicted = regr.predict(atribut1)\n",
    "\n",
    "# Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "plt.figure()\n",
    "ax = plt.scatter(x[:,0], y)\n",
    "plt.plot(atribut1[:,0], predicted, 'r')\n",
    "\n",
    "# Mostrem l'error (MSE i R2)\n",
    "MSE = mse(y, predicted)\n",
    "r2 = r2_score(y, predicted)\n",
    "\n",
    "print(\"Mean squeared error: \", MSE)\n",
    "print(\"R2 score: \", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop mostrats de manera adient, (en forma de taula, i/o de gràfics si la dimensionalitat ho permet) els resultats aconseguits amb la regressió, avaluarem de manera independent la idonietat de cadascun dels atributs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Per a assegurar-nos que el model s'ajusta be a dades noves, no vistes, \n",
    "cal evaluar-lo en un conjunt de validacio (i un altre de test en situacions reals).\n",
    "Com que en aquest cas no en tenim, el generarem separant les dades en \n",
    "un 80% d'entrenament i un 20% de validació.\n",
    "\"\"\"\n",
    "def split_data(x, y, train_ratio=0.8):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "# Dividim dades d'entrenament\n",
    "x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "for i in range(x_train.shape[1]):\n",
    "    x_t = x_train[:,i] # seleccionem atribut i en conjunt de train\n",
    "    x_v = x_val[:,i] # seleccionem atribut i en conjunt de val.\n",
    "    x_t = np.reshape(x_t,(x_t.shape[0],1))\n",
    "    x_v = np.reshape(x_v,(x_v.shape[0],1))\n",
    "\n",
    "    regr = regression(x_t, y_train)    \n",
    "    error = mse(y_val, regr.predict(x_v)) # calculem error\n",
    "    r2 = r2_score(y_val, regr.predict(x_v))\n",
    "\n",
    "    print(\"Error en atribut %d: %f\" %(i, error))\n",
    "    print(\"R2 score en atribut %d: %f\" %(i, r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan es treballa en dades n-dimensionals (més d'un atribut), una opció és reduir la seva n-dimensionalitat aplicant un Principal Component Analysis (PCA) i quedar-se amb els primers 2 o 3 components, obtenint unes dades que (ara sí) poden ser visualitzables en el nou espai. Existeixen altres embeddings de baixa dimensionalitat on poder visualitzar les dades?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Així es podrà contestar a aquestes **preguntes**:\n",
    "\n",
    "1. Quin són els atributs més importants per fer una bona predicció?\n",
    "\n",
    "2. Amb quin atribut s'assoleix un MSE menor?\n",
    "\n",
    "3. Quina correlació hi ha entre els atributs de la vostra base de dades?\n",
    "\n",
    "4. Com influeix la normalització en la regressió?\n",
    "\n",
    "5. Com millora la regressió quan es filtren aquells atributs de les mostres que no contenen informació?\n",
    "\n",
    "6. Si s'aplica un PCA, a quants components es redueix l'espai? Per què?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (A): El descens del gradient  \n",
    "\n",
    "En aquest exercici, es tracta d'implementar en python el procés de descent del gradient explicat a les classes de teoria, i comparar-lo amb els resultats obtinguts amb l'apartat (B). \n",
    "\n",
    "$$J(w) = \\frac{1}{2m} \\left[ \\sum^m_{i=1}(f(x^{i}; w) - y^{i})^2 + \\lambda\\sum_{j=1}^{n}(w_{j}^2) \\right]$$\n",
    "\n",
    "Fixeu-vos que $J$ retorna el `mse`. Per a trobar $w_j$, repetir fins convergència:\n",
    "$$w_0 = w_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot 1$$\n",
    "$$w_j = w_j - \\alpha \\left[\\frac{1}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot x_{j}^{i} - \\frac{\\lambda}{m}w_{j} \\right]$$\n",
    "\n",
    "\n",
    "ó:\n",
    "\n",
    "$$w_{j} := w_{j} \\left(1-\\alpha \\frac{\\lambda}{m} \\right) - \\alpha\\frac{\\lambda}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot x_{j}^{i}$$\n",
    "\n",
    "On si considerem un regressor lineal (el model és una recta), llavors $w_0$ i $w_1$ representen, respectivament, la $b$ i $a$ de la fòrmula de la recta: \n",
    "\n",
    "$$h_\\theta(x^{(i)}) = ax + b$$\n",
    "\n",
    "$\\alpha$ és el learning rate, i $h_\\theta(x^{(i)})$ és la funció que fa la regressió, és a dir, la funció que prediu el valor de $y^{(i)}$ donat un(s) atribut(s) concret(s) $x^{(i)}$.\n",
    "\n",
    "Així, tenint calculat el model en l'últim punt del primer exercici, ja sabeu quin resultat hauríeu d'obtenir. O no, perquè la vostra implementació pot ser millor! En concret, es tracta de desenvolupar aquestes tasques:\n",
    "\n",
    "* Definir la funció de cost i del gradient\n",
    "\n",
    "* Estudiar com l'ús de regularitzadors afecta el resultat: overfitting, underfitting, etc. \n",
    "\n",
    "* Visualització de les dades a analitzar i explicació pas a pas del procediment   \n",
    "\n",
    "* Visualització del procés de descens de gradient \n",
    "\n",
    "* Modificar el learning rate i el nombre d'iteracions \n",
    "\n",
    "<img src=\"images/gradient_descent.png\">\n",
    "\n",
    "Per a la implementació us podeu basar en el següent esquelet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(object):\n",
    "    def __init__(self, w0, w1, alpha):\n",
    "        # Inicialitzem w0 i w1 (per ser ampliat amb altres w's)\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # implementar aqui la funció de prediccio\n",
    "        pass\n",
    "    \n",
    "    def __update(self, hy, y):\n",
    "        # actualitzar aqui els pesos donada la prediccio (hy) i la y real.\n",
    "        pass\n",
    "    \n",
    "    def train(self, max_iter, epsilon):\n",
    "        # Entrenar durant max_iter iteracions o fins que la millora sigui inferior a epsilon\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'últim pas serà validar el regressor trobat pel descent del gradient desenvolupat en aquest apartat visualment, aplicat a un model de recta i un model de pla. Per a això, caldrà considerar el millor atribut identificat en el primer punt de l'anterior entrega per visualitzar la línia regressora en 2D (podeu mostrar dades 2d amb la funció scatter). Després, dos dels atributs identificats a l'últim punt del primer exercici per visualitzar el pla regressor en 3D (En el cas 3D l’scatter s’ha de fer sobre una figura amb projecció 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Creem figura 3d\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "# generem dades 3D d'exemple\n",
    "x_val = np.random.random((100, 2))\n",
    "y_val = np.random.random((100, 1))\n",
    "regr = regression(x_val, y_val)\n",
    "predX3D = regr.predict(x_val)\n",
    "\n",
    "# Afegim els 1's\n",
    "A = np.hstack((x_val,np.ones([x_val.shape[0],1])))\n",
    "w = np.linalg.lstsq(A,predX3D)[0]\n",
    "\n",
    "#Dibuixem\n",
    "#1r creem una malla acoplada a la zona de punts per tal de representar el pla\n",
    "malla = (range(20) + 0 * np.ones(20)) / 10 \n",
    "malla_x1 =  malla * (max(x_val[:,0]) - min(x_val[:,0]))/2 + min(x_val[:,0])\n",
    "malla_x2 =  malla * (max(x_val[:,1]) - min(x_val[:,1]))/2 + min(x_val[:,1])\n",
    "\n",
    "#la funcio meshgrid ens aparella un de malla_x1 amb un de malla_x2, per atot\n",
    "#element de mallax_1 i per a tot element de malla_x2.\n",
    "xplot, yplot = np.meshgrid(malla_x1 ,malla_x2)\n",
    "\n",
    "# Cal desnormalitzar les dades\n",
    "def desnormalitzar(x, mean, std):\n",
    "    return x * std + mean\n",
    "\n",
    "#ara creem la superficies que es un pla\n",
    "zplot = w[0] * xplot + w[1] * yplot + w[2]\n",
    "\n",
    "#Dibuixem punts i superficie\n",
    "plt3d = plt.figure('Coeficiente prismatico -- Relacio longitud desplacament 3D', dpi=100.0).gca(projection='3d')\n",
    "plt3d.plot_surface(xplot,yplot,zplot, color='red')\n",
    "plt3d.scatter(x_val[:,0],x_val[:,1],y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Així es podrà contestar a aquestes preguntes:\n",
    "\n",
    "1. Com influeixen tots els paràmetres en el procés de descens? Quins valors de learning rate convergeixen més ràpid a la solució òptima? Com influeix la inicialització del model en el resultat final? \n",
    "\n",
    "2. Quines funcions polinomials (de diferent grau, de diferents combinacions d'atributs, ...) heu escollit per ser apreses amb el vostre descens del gradient? quina ha donat el millor resultat (en error i rapidesa en convergència)?\n",
    "\n",
    "3. Utilitzeu el regularitzador en la fòrmula de funció de cost i descens del gradient i proveu polinomis de diferent grau. Com afecta el valor del regularitzador?\n",
    "\n",
    "3. Quina diferència (quantitativa i qualitativa) hi ha entre el vostre regressor i el de la llibreria ?\n",
    "\n",
    "4. Té sentit el model (polinomial) trobat quan es visualitza sobre les dades? \n",
    "\n",
    "5. Ajuda la visualització a identificar aquelles mostres per a les que el regressor obté els pitjors resultats de predicció? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
