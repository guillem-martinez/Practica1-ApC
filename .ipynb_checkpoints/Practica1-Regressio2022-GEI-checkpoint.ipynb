{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducció a la pràctica 1: primers passos\n",
    "\n",
    "## Objectius\n",
    "\n",
    "Els objectius d'aquesta pràctica són:\n",
    "\n",
    "* Aplicar models de regressió, ficant l'èmfasi en: \n",
    "    1. Analitzar els atributs per seleccionar els més representatius i normalitzar-los.\n",
    "    2. Avaluar correctament l'error del model \n",
    "    3. Visualitzar les dades i el model resultant\n",
    "    4. Saber aplicar el procès de descens del gradient\n",
    "\n",
    "* Ésser capaç d'aplicar tècniques de regressió en casos reals\n",
    "\n",
    "* Validar els resultats en dades reals\n",
    "\n",
    "* Fomentar la capacitat per presentar resultats tècnics d'aprenentatge computacional de forma adequada davant altres persones\n",
    "\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "Aquest ``jupyter notebook`` està compost de blocs de text i codi, recordeu que hi ha blocs de codi que depenen de que blocs anteriors hagin estat executats. \n",
    "\n",
    "El codi d'aquest notebook és modificable i us recomanem que feu canvis i en comproveu els resultats.\n",
    "\n",
    "**Per a executar el notebook: cal que instal.leu [jupyter notebook](http://jupyter.readthedocs.io/en/latest/install.html).**\n",
    "\n",
    "\n",
    "### Guia d'instal.lació de les llibreries\n",
    "\n",
    "\n",
    "És molt recomanable que utilitzeu Linux, ja que agilitza la instal.lació de les llibreries. També es recomana utilitzar **Anaconda**, una distribucó de python multiplataforma que permet instal.lar llibreries fàcilment i l'IDE d'spyder o PyCharm.\n",
    "\n",
    "Donat que teniu conda o pypi (pip) (aquest segon es pot instal.lar amb ``apt-get``), heu d'instal.lar els següents paquets (exemple en pypi):\n",
    "\n",
    "```\n",
    "sudo pip install numpy\n",
    "sudo pip install scikit-learn\n",
    "sudo pip install matplotlib\n",
    "sudo pip install scipy\n",
    "```\n",
    "\n",
    "En el cas d'Anaconda, substituir ``sudo pip`` per ``conda``.\n",
    "\n",
    "En el cas del matplotlib, si us dona errors en Ubuntu Linux (`FileNotFoundError: [Errno 2] No such file or directory: 'latex': 'latex'`), cal instal·lar el paquet `texlive-full` (`sudo apt install texlive-full`) que ocupa 3-4GB. Si només ho voleu per aquesta pràctica, podeu provar amb el `textlive-base` (uns 100MB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació i entregues de la pràctica 1\n",
    "\n",
    "En la pràctica 1, es presenten diversos problemes per comprendre els mètodes de regressió numèrica. \n",
    "\n",
    "Les entregues s'organitzen en tres nivells d'assoliment dels objectius, incrementals: apartat **C (sobre 5 punts)**, assoliment baix, apartat **B, (sobre 3 punts)**, assoliment mig i apartat **A, (sobre 2 punts)**, assoliment alt. La suma dels 3 apartats serà la nota final de la pràctica 1.\n",
    "\n",
    "Per aprovar la pràctica és requisit necessari completar satisfactòriament els problemes d'assoliment baix (C), demostrant així una comprensió mínima de la matèria. Per tant, la superació de la pràctica 1 estarà condicionada a la presentació de la documentació sobre l'apartat (C), i serà opcional realitzar els apartats (B i A).\n",
    "\n",
    "Resumint, la pràctica 1 conté 3 apartats:\n",
    "\n",
    "* apartat C. serà obligatori per aprovar la pràctica 1 (amb un 5.0)\n",
    "* apartat B. serà opcional i val fins a 3 punts (cal haver fet el apartat C).\n",
    "* apartat A. serà opcional i val fins a 2 punts (cal haver fet el apartat C i B).\n",
    "\n",
    "\n",
    "### Sessió de treball i sessió d'avaluació\n",
    "\n",
    "La sessió de treball del 29 de setembre, està orientada a que els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les bases de dades que us han estat assignades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades.\n",
    "\n",
    "En definitiva, l'objectiu de la sessió de treball és que al sortir tingueu clar com són les vostres dades, què cal entregar i com implementar cada apartat C, B i A. \n",
    "\n",
    "En la següent sessió d'avaluació del 13 d'octubre, la màxima puntuació per la **pràctica 1 de regressió** s'aconsegueix resolent els problemes dels apartats (B i A), d'entrega opcional. Caldrà pujar al Caronte abans de les 23:59h del dimecres 12 d'octubre un ZIP amb el codi, la documentació i el ppt (10 minuts).\n",
    "\n",
    "* Entrega ZIP \n",
    "   1. Memòria explicant els resultats trobats en la base de dades que heu treballat, detallant el passos seguits (60% de la nota). \n",
    "   2. Codi python desenvolupat (30% de la nota)\n",
    "   3. Presentació amb els resultats 10 min màxim (10% de la nota)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Material de la pràctica 1\n",
    "\n",
    "1. Bases de dades a Kaggle: cada grup utilitzarà les bases de dades que se li hagin assignat. \n",
    "2. Codi d'exemple (aquest document).\n",
    "3. Apunts de l'assignatura.\n",
    "4. Llibreries de python: scikit-learn, numpy, scipy, matplotlib.\n",
    "\n",
    "### Bases de Dades\n",
    "\n",
    "| #  | URL                                                                      | GRUP        |\n",
    "|----|--------------------------------------------------------------------------|-------------|\n",
    "| 1  | https://www.kaggle.com/mohansacharya/graduate-admissions                 | GPA101-0830 |\n",
    "| 2  | https://www.kaggle.com/primaryobjects/voicegender                        | GPA102-0830 |\n",
    "| 3  | https://www.kaggle.com/mirichoi0218/insurance                            | GPA103-0830 |\n",
    "| 4  | https://www.kaggle.com/rhuebner/human-resources-data-set                 | GPA104-0830 |\n",
    "| 5  | https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009          | GPA105-0830 |\n",
    "| 6  | https://www.kaggle.com/kumarajarshi/life-expectancy-who                  | GPA201-0930 |\n",
    "| 7  | https://www.kaggle.com/marklvl/bike-sharing-dataset                      | GPA202-0930 |\n",
    "| 8  | https://www.kaggle.com/vikrishnan/boston-house-prices                    | GPA203-0930 |\n",
    "| 9  | https://www.kaggle.com/imnikhilanand/heart-attack-prediction             | GPA204-0930 |\n",
    "| 10 | https://www.kaggle.com/dongeorge/beer-consumption-sao-paulo              | GPA205-0930 |\n",
    "| 11 | https://www.kaggle.com/anderas/car-consume                               | GPA301-1030 |\n",
    "| 12 | https://www.kaggle.com/edgarhuichen/nba-players-career-game-log          | GPA302-1030 |\n",
    "| 13 | https://www.kaggle.com/dipam7/student-grade-prediction                   | GPA303-1030 |\n",
    "| 14 | https://www.kaggle.com/navoneel/fta-data                                 | GPA304-1030 |\n",
    "| 15 | https://www.kaggle.com/maajdl/yeh-concret-data                           | GPA305-1030 |\n",
    "| 16 | https://www.kaggle.com/mrisdal/combo17-galaxy-dataset                    | GPA401-1130 |\n",
    "| 17 | https://www.kaggle.com/elikplim/forest-fires-data-set                    | GPA402-1130 |\n",
    "| 18 | https://www.kaggle.com/rodolfomendes/abalone-dataset                     | GPA403-1130 |\n",
    "| 19 | https://www.kaggle.com/ravisane1/market-price-of-onion-2020              | GPA404-1130 |\n",
    "| 20 | https://www.kaggle.com/fredgirod/web-crawler-for-real-estate-market      | GPA405-1130 |\n",
    "| 21 | https://www.kaggle.com/avikasliwal/used-cars-price-prediction            | GPA501-1230 |\n",
    "| 22 | https://www.kaggle.com/shebrahimi/financial-distress                     | GPA502-1230 |\n",
    "| 23 | https://www.kaggle.com/usda/the-national-summary-of-meats                | GPA503-1230 |\n",
    "| 24 | https://www.kaggle.com/uciml/electric-power-consumption-data-set         | GPA504-1230 |\n",
    "| 25 | https://www.kaggle.com/manishkc06/engineering-graduate-salary-prediction | GPA505-1230 |\n",
    "| 26 | https://www.kaggle.com/jsphyg/tipping                                    | GPA601-1530 |\n",
    "| 27 | https://www.kaggle.com/amarpandey/world-life-expectancy-18002016         | GPA602-1530 |\n",
    "| 28 | https://www.kaggle.com/snehal1405/yellow-stone-national-park             | GPA603-1530 |\n",
    "| 29 | https://www.kaggle.com/nisargpatel/automobiles                           | GPA604-1530 |\n",
    "| 30 | https://www.kaggle.com/sabermalek/tapds                                  | GPA605-1530 |\n",
    "| 31 | https://www.kaggle.com/noordeen/insurance-premium-prediction             | GPA606-1530 |\n",
    "| 32 | https://www.kaggle.com/olgabelitskaya/russian-financial-indicators       | GPA607-1530 |\n",
    "| 33 | https://www.kaggle.com/ramkumarr02/deodorant-instant-liking-data         | GPA608-1530 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (C): Analitzant Dades\n",
    "\n",
    "L'objectiu d'aquest primer apartat serà conèixer la base de dades que es té entre mans. S'han d'analitzar els diferents atributs que la composen, entendre'ls i, si no està estipulat, **caldrà fixar quin es l'atribut objectiu a predir de tots els que hi ha a la base de dades**, justificant el per què de la decisió (és útil i representatiu pel problema, per exemple, donat un conjunt de dades sobre persones: edat, gènere, pes, alçada, risc de patir càncer, aquesta última pot ser justificada com la de més interés). També podeu mirar que l'atribut objectiu tingui valors que canvien. Per exemple, no té sentit predir un atribut on el 99% dels valors són 0, i hi ha algun 1.\n",
    "\n",
    "Ara podeu veure un exemple amb una base de dades **dummy** que creem nosaltres mateixos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionalitat de la BBDD: (134, 12)\n",
      "Dimensionalitat de les entrades X (134, 2)\n",
      "Dimensionalitat de l'atribut Y (134,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualitzarem només 3 decimals per mostra\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Funcio per a llegir dades en format csv\n",
    "def load_dataset(path):\n",
    "    dataset = pd.read_csv(path, header=0, delimiter=',')\n",
    "    return dataset\n",
    "\n",
    "# Carreguem dataset d'exemple\n",
    "datasetBeef = load_dataset(\"data/Beef History.csv\")\n",
    "clean = [\"%\",\"%.1\",\"%.2\",\"%.3\",\"%.4\",\"%.5\",\"%.6\",\"%.7\",\"%.8\",\"%.9\",\"%.10\",\"%.11\",\"%.12\",\"Y1\",\"Y2\",\"Y3\",\"Y4\",\"Y5\"]\n",
    "\n",
    "for i in clean:\n",
    "    datasetBeef = datasetBeef.drop(i,axis=1)\n",
    "\n",
    "\n",
    "dataBeef = datasetBeef.values\n",
    "\n",
    "\n",
    "xBeef = dataBeef[:, :2]\n",
    "yBeef = dataBeef[:, 2]\n",
    "\n",
    "\n",
    "print(\"Dimensionalitat de la BBDD:\", datasetBeef.shape)\n",
    "print(\"Dimensionalitat de les entrades X\", xBeef.shape)\n",
    "print(\"Dimensionalitat de l'atribut Y\", yBeef.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcions a utilitzar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetReplace(ds):\n",
    "    ds = ds.replace(\"%\", \"\", regex=True)\n",
    "    ds = ds.replace(\",\", \"\", regex=True)\n",
    "    return ds\n",
    "\n",
    "def nullCounter(ds):\n",
    "    print(ds.isnull().sum())\n",
    "    print(ds.shape)\n",
    "    \n",
    "def clearNaNYears(ds):\n",
    "    ds = ds.iloc[:-6]\n",
    "    ds = ds.dropna(subset=['YEAR'], how=\"all\")\n",
    "    ds = ds.reset_index(drop=True)\n",
    "    return ds\n",
    "\n",
    "def printColumnTypes(ds):\n",
    "    for line in ds.columns:\n",
    "        print(line, type(ds[line][0]))\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(ds)\n",
    "    print(ds.shape)\n",
    "    \n",
    "def columnSelector(ds):\n",
    "    nullValues = ds.isnull().sum()\n",
    "    nullValuesDict = nullValues.to_dict()\n",
    "    to_drop = []\n",
    "    to_fill = []\n",
    "\n",
    "    for key in nullValuesDict:\n",
    "        if(nullValuesDict[key]/len(ds.axes[0]) >= 0.5):\n",
    "            print(nullValuesDict[key])\n",
    "            to_drop.append(key) ##Eliminar columnes\n",
    "        else:\n",
    "            to_fill.append(key) ##Omplir amb 0s\n",
    "            \n",
    "    return to_drop,to_fill\n",
    "\n",
    "def fillDropColumns(ds, drop, fill, wList, bList):\n",
    "    for i in drop:\n",
    "        if i in wList:\n",
    "            drop.remove(i)\n",
    "            \n",
    "    for j in fill:\n",
    "        if j in bList:\n",
    "            fill.remove(j)\n",
    "            drop.append(i)\n",
    "    \n",
    "        \n",
    "    ds.drop(columns=drop, inplace=True) ##Eliminem les columnes\n",
    "\n",
    "    for key in fill:\n",
    "        ds[key] = ds[key].fillna(0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Carrgar los 3 datasets <br>\n",
    "2 Para cada dataset count columnas de lo que hay vacia print al profe de semejante basura<br>\n",
    "3 Borrar columnas que no tienen en comun<br>\n",
    "4 Cleaning de los data, ni un Nan<br>\n",
    "5 Hacer pandas.core de la misma talla (_, 1) para labels, pd.concat(_,_,axis=1)<br>\n",
    "6 --> Repetir punto 2<br>\n",
    "7 Las que tienen en comun con mas de 50% de nan borrarlas<br>\n",
    "8 Guardar, nuevo dataset increible, dataset.csv muy GOD<br>\n",
    "9 Plot del compañero del kaggle url: https://www.kaggle.com/code/jihyeseo/beef-price-time-series-since-1930s<br>\n",
    "df.plot(x = 'YEAR', y = 'POUNDS GRADED') --> Para Gaussiana<br>\n",
    "10 Normalizar datos<br>\n",
    "11 Separar en train test, train test split<br>\n",
    "12 Entrenar modelo (fit)<br>\n",
    "13 Grid search para<br>\n",
    "https://www.kaggle.com/datasets/imnikhilanand/heart-attack-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo 2 lineas de datos estimados, decidimos borrarlos para evitar posibles outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "    YEAR POUNDS GRADED PRIME  CHOICE SELECT  STNDRD COMRCL UTILITY CUTTER  \\\n",
      "60  1985        12,776   457  11,875    386  11.000      8      35      4   \n",
      "61  1986         9,786   325   9,155    277   5.000      2      20      2   \n",
      "62  1987        12,127   382  11,462    265   2.000      1      15    NaN   \n",
      "63  1988        12,567   379  11,597    579   2.000    NaN      10    NaN   \n",
      "64  1989        12,890   335  11,105  1,433   1.000      1      11      3   \n",
      "65   NaN           NaN   NaN     NaN    NaN     NaN    NaN     NaN    NaN   \n",
      "66  1990        12,345   255  10,172  1,906     NaN      1      11    NaN   \n",
      "67  1991        12,919   289  10,193  2,427     NaN      1       9    NaN   \n",
      "68  1992        13,816   286  10,315  3,203   4.000      1       7    NaN   \n",
      "69  1993        15,572   326  10,377  4,846   8.000      3      12    NaN   \n",
      "\n",
      "    CANNER    S/H %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "60     NaN  68.5%                           57.6%  \n",
      "61     NaN  69.0%                           51.5%  \n",
      "62     NaN  64.3%                           54.0%  \n",
      "63     NaN  66.0%                           56.4%  \n",
      "64   1.000  78.4%                           66.9%  \n",
      "65     NaN    NaN                             NaN  \n",
      "66     NaN  86.7%                           74.3%  \n",
      "67     NaN  92.4%                           79.8%  \n",
      "68     NaN  95.2%                           84.5%  \n",
      "69     NaN  95.1%                           81.3%  \n"
     ]
    }
   ],
   "source": [
    "##Beef\n",
    "\n",
    "datasetBeef = datasetBeef.replace(\".*\\*\", \"*\", regex=True)\n",
    "estimatedValues = datasetBeef[datasetBeef['YEAR'] == \"*\"]\n",
    "print(len(estimatedValues))\n",
    "datasetBeef = datasetBeef.replace(\"\\*\", pd.NA, regex=True)\n",
    "\n",
    "print(datasetBeef[60:70])\n",
    "\n",
    "datasetBeef = datasetReplace(datasetBeef) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunes bases de dades tenen valors no existents. Numpy els representa amb ``np.nan``. Per a treure'ls, podeu fer: ``dades[np.isnan(dades)] = valor``. Podeu mirar com afecten diferents estratègies d'assignar ``valor``. Per exemple, pot ser 0, la mitja, la mediana, .... També podeu analitzar si hi ha algun atribut perdut (que té molts valors no existents) i valorar si eliminar directament l'atribut.\n",
    "\n",
    "Hi ha vegades que el fitxer .csv utilitza una coma ',' en comptes d'un punt decimal '.', fent que cada atribut sigui considerat com un ``string``. Per tant, a part d'eliminar les files (mostres) que continguin ``NaN``, cal convertir les ',' a '.' per a poder convertir els valors a ``float``.\n",
    "\n",
    "A més, utilitzeu la llibreria pandas, i no `np.genfromtxt()` ja que llegeix només valors numèrics, i els NaN els converteix a string. Si esteu empenyats en utilitzar `np.genfromtxt()`, caldrà posar-li com a paràmetre `dtype=object`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR                                44\n",
      "POUNDS GRADED                       49\n",
      "PRIME                               70\n",
      "CHOICE                              65\n",
      "SELECT                              65\n",
      "STNDRD                              78\n",
      "COMRCL                              69\n",
      "UTILITY                             67\n",
      "CUTTER                              92\n",
      "CANNER                             111\n",
      "S/H                                101\n",
      "%  of FEDERAL  SLAUGHTER\\t BEEF     49\n",
      "dtype: int64\n",
      "(134, 12)\n"
     ]
    }
   ],
   "source": [
    "nullCounter(datasetBeef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos eliminar directamente las lineas que contengan un NaN, no es viable, solo queda una linea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12)\n"
     ]
    }
   ],
   "source": [
    "newDataset2 = datasetBeef.dropna()\n",
    "print(newDataset2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "YEAR <class 'str'>\n",
      "POUNDS GRADED <class 'str'>\n",
      "PRIME <class 'float'>\n",
      "CHOICE <class 'float'>\n",
      "SELECT <class 'float'>\n",
      "STNDRD <class 'numpy.float64'>\n",
      "COMRCL <class 'float'>\n",
      "UTILITY <class 'float'>\n",
      "CUTTER <class 'float'>\n",
      "CANNER <class 'numpy.float64'>\n",
      "S/H <class 'float'>\n",
      "%  of FEDERAL  SLAUGHTER\t BEEF <class 'str'>\n",
      "-------------------------------------------------------\n",
      "    YEAR POUNDS GRADED PRIME CHOICE SELECT  STNDRD COMRCL UTILITY CUTTER  \\\n",
      "0   1930            69   NaN    NaN    NaN     NaN    NaN     NaN    NaN   \n",
      "1   1931           159   NaN    NaN    NaN     NaN    NaN     NaN    NaN   \n",
      "2   1932           208   NaN    NaN    NaN     NaN    NaN     NaN    NaN   \n",
      "3   1933           238   NaN    NaN    NaN     NaN    NaN     NaN    NaN   \n",
      "4   1934           262   NaN    NaN    NaN     NaN    NaN     NaN    NaN   \n",
      "..   ...           ...   ...    ...    ...     ...    ...     ...    ...   \n",
      "79  2011         20342   717  13170   6204  68.000      3      16    NaN   \n",
      "80  2012         19952   703  12889   6102  63.000      3      15    NaN   \n",
      "81  2013         19755   758  13038   5788  11.000      4      16    NaN   \n",
      "82  2014         19234   842  13157   5067   8.000      4      18    NaN   \n",
      "83  2015         23720   999  13409   3971   3.000      3      19    NaN   \n",
      "\n",
      "    CANNER   S/H %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "0      NaN   NaN                             1.2  \n",
      "1      NaN   NaN                             2.7  \n",
      "2      NaN   NaN                             3.8  \n",
      "3      NaN   NaN                             3.9  \n",
      "4      NaN   NaN                             3.3  \n",
      "..     ...   ...                             ...  \n",
      "79     NaN  95.0                            80.1  \n",
      "80     NaN  94.2                            79.7  \n",
      "81     NaN  94.2                            79.7  \n",
      "82     NaN  94.3                            80.9  \n",
      "83     NaN  94.4                            80.9  \n",
      "\n",
      "[84 rows x 12 columns]\n",
      "(84, 12)\n",
      "Per comptar el nombre de valors no existents beef:\n",
      "YEAR                                0\n",
      "POUNDS GRADED                       1\n",
      "PRIME                              22\n",
      "CHOICE                             17\n",
      "SELECT                             17\n",
      "STNDRD                             30\n",
      "COMRCL                             21\n",
      "UTILITY                            19\n",
      "CUTTER                             44\n",
      "CANNER                             62\n",
      "S/H                                51\n",
      "%  of FEDERAL  SLAUGHTER\\t BEEF     1\n",
      "dtype: int64\n",
      "(84, 12)\n"
     ]
    }
   ],
   "source": [
    "##Netejant les dades\n",
    "print(type(datasetBeef))\n",
    "\n",
    "##Beef\n",
    "datasetBeef = clearNaNYears(datasetBeef)\n",
    "\n",
    "printColumnTypes(datasetBeef)\n",
    "print(\"Per comptar el nombre de valors no existents beef:\")\n",
    "nullCounter(datasetBeef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 <class 'numpy.int64'>\n",
      "YEAR <class 'numpy.int64'>\n",
      "POUNDS GRADED <class 'numpy.float64'>\n",
      "PRIME <class 'numpy.float64'>\n",
      "CHOICE <class 'numpy.float64'>\n",
      "SELECT <class 'numpy.float64'>\n",
      "STNDRD <class 'numpy.float64'>\n",
      "COMRCL <class 'numpy.float64'>\n",
      "UTILITY <class 'numpy.float64'>\n",
      "CUTTER <class 'numpy.float64'>\n",
      "CANNER <class 'numpy.float64'>\n",
      "S/H <class 'numpy.float64'>\n",
      "%  of FEDERAL  SLAUGHTER\t BEEF <class 'numpy.float64'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POUNDS GRADED</th>\n",
       "      <th>PRIME</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SELECT</th>\n",
       "      <th>STNDRD</th>\n",
       "      <th>COMRCL</th>\n",
       "      <th>UTILITY</th>\n",
       "      <th>CUTTER</th>\n",
       "      <th>CANNER</th>\n",
       "      <th>S/H</th>\n",
       "      <th>%  of FEDERAL  SLAUGHTER\\t BEEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>83.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.500</td>\n",
       "      <td>1972.524</td>\n",
       "      <td>11102.349</td>\n",
       "      <td>536.129</td>\n",
       "      <td>8749.836</td>\n",
       "      <td>3205.522</td>\n",
       "      <td>61.648</td>\n",
       "      <td>165.825</td>\n",
       "      <td>151.062</td>\n",
       "      <td>122.700</td>\n",
       "      <td>2.727</td>\n",
       "      <td>89.191</td>\n",
       "      <td>56.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24.393</td>\n",
       "      <td>25.268</td>\n",
       "      <td>7057.610</td>\n",
       "      <td>288.612</td>\n",
       "      <td>4176.600</td>\n",
       "      <td>2795.323</td>\n",
       "      <td>71.763</td>\n",
       "      <td>484.817</td>\n",
       "      <td>302.641</td>\n",
       "      <td>310.018</td>\n",
       "      <td>2.529</td>\n",
       "      <td>11.261</td>\n",
       "      <td>27.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1930.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>230.000</td>\n",
       "      <td>176.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>64.300</td>\n",
       "      <td>1.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.750</td>\n",
       "      <td>1950.750</td>\n",
       "      <td>6489.000</td>\n",
       "      <td>328.250</td>\n",
       "      <td>5594.500</td>\n",
       "      <td>1108.000</td>\n",
       "      <td>5.250</td>\n",
       "      <td>2.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>6.750</td>\n",
       "      <td>1.000</td>\n",
       "      <td>92.400</td>\n",
       "      <td>49.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.500</td>\n",
       "      <td>1973.500</td>\n",
       "      <td>12118.000</td>\n",
       "      <td>552.500</td>\n",
       "      <td>10800.000</td>\n",
       "      <td>1776.000</td>\n",
       "      <td>28.500</td>\n",
       "      <td>19.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>94.900</td>\n",
       "      <td>57.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.250</td>\n",
       "      <td>1994.250</td>\n",
       "      <td>17476.000</td>\n",
       "      <td>720.750</td>\n",
       "      <td>11588.500</td>\n",
       "      <td>6153.000</td>\n",
       "      <td>78.750</td>\n",
       "      <td>55.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>42.750</td>\n",
       "      <td>3.000</td>\n",
       "      <td>95.500</td>\n",
       "      <td>81.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83.000</td>\n",
       "      <td>2015.000</td>\n",
       "      <td>23720.000</td>\n",
       "      <td>1369.000</td>\n",
       "      <td>13409.000</td>\n",
       "      <td>8279.000</td>\n",
       "      <td>263.000</td>\n",
       "      <td>2421.000</td>\n",
       "      <td>1560.000</td>\n",
       "      <td>1470.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>96.800</td>\n",
       "      <td>94.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     YEAR  POUNDS GRADED    PRIME    CHOICE   SELECT  STNDRD  \\\n",
       "count      84.000   84.000         83.000   62.000    67.000   67.000  54.000   \n",
       "mean       41.500 1972.524      11102.349  536.129  8749.836 3205.522  61.648   \n",
       "std        24.393   25.268       7057.610  288.612  4176.600 2795.323  71.763   \n",
       "min         0.000 1930.000         69.000    6.000   230.000  176.000   1.000   \n",
       "25%        20.750 1950.750       6489.000  328.250  5594.500 1108.000   5.250   \n",
       "50%        41.500 1973.500      12118.000  552.500 10800.000 1776.000  28.500   \n",
       "75%        62.250 1994.250      17476.000  720.750 11588.500 6153.000  78.750   \n",
       "max        83.000 2015.000      23720.000 1369.000 13409.000 8279.000 263.000   \n",
       "\n",
       "        COMRCL  UTILITY   CUTTER  CANNER    S/H  \\\n",
       "count   63.000   65.000   40.000  22.000 33.000   \n",
       "mean   165.825  151.062  122.700   2.727 89.191   \n",
       "std    484.817  302.641  310.018   2.529 11.261   \n",
       "min      1.000    1.000    1.000   1.000 64.300   \n",
       "25%      2.000   11.000    6.750   1.000 92.400   \n",
       "50%     19.000   35.000   15.000   2.000 94.900   \n",
       "75%     55.000  156.000   42.750   3.000 95.500   \n",
       "max   2421.000 1560.000 1470.000  10.000 96.800   \n",
       "\n",
       "       %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
       "count                           83.000  \n",
       "mean                            56.472  \n",
       "std                             27.043  \n",
       "min                              1.200  \n",
       "25%                             49.350  \n",
       "50%                             57.600  \n",
       "75%                             81.000  \n",
       "max                             94.900  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetBeef.to_csv(\"data/BeefDataset.csv\")\n",
    "datasetBeef = load_dataset(\"data/BeefDataset.csv\")\n",
    "for line in datasetBeef.columns:\n",
    "    print(line, type(datasetBeef[line][0]))\n",
    "    \n",
    "datasetBeef.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POUNDS GRADED:      Unnamed: 0  YEAR  POUNDS GRADED  PRIME  CHOICE  SELECT  STNDRD  COMRCL  \\\n",
      "50          50  1982            NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "    UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "50      NaN                              NaN  \n",
      "%  of FEDERAL  SLAUGHTER\t BEEF:      Unnamed: 0  YEAR  POUNDS GRADED  PRIME  CHOICE  SELECT  STNDRD  COMRCL  \\\n",
      "50          50  1982            NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "    UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "50      NaN                              NaN  \n",
      "PRIME:      Unnamed: 0  YEAR  POUNDS GRADED  PRIME   CHOICE   SELECT  STNDRD   COMRCL  \\\n",
      "0            0  1930         69.000    NaN      NaN      NaN     NaN      NaN   \n",
      "1            1  1931        159.000    NaN      NaN      NaN     NaN      NaN   \n",
      "2            2  1932        208.000    NaN      NaN      NaN     NaN      NaN   \n",
      "3            3  1933        238.000    NaN      NaN      NaN     NaN      NaN   \n",
      "4            4  1934        262.000    NaN      NaN      NaN     NaN      NaN   \n",
      "5            5  1935        268.000    NaN      NaN      NaN     NaN      NaN   \n",
      "6            6  1936        450.000    NaN      NaN      NaN     NaN      NaN   \n",
      "7            7  1937        408.000    NaN      NaN      NaN     NaN      NaN   \n",
      "12          12  1942       1478.000    NaN  439.000  560.000     NaN  284.000   \n",
      "13          13  1943       6691.000    NaN 1297.000 2081.000     NaN 1544.000   \n",
      "14          14  1944       8328.000    NaN  865.000 2329.000     NaN 2104.000   \n",
      "15          15  1945       9067.000    NaN 1258.000 2791.000     NaN 2421.000   \n",
      "16          16  1946       6681.000    NaN 1049.000 2512.000     NaN 1710.000   \n",
      "18          18  1948       2022.000    NaN      NaN      NaN     NaN      NaN   \n",
      "19          19  1949       2280.000    NaN      NaN      NaN     NaN      NaN   \n",
      "20          20  1950       2262.000    NaN      NaN      NaN     NaN      NaN   \n",
      "21          21  1951       6250.000    NaN      NaN      NaN     NaN      NaN   \n",
      "22          22  1952       8784.000    NaN      NaN      NaN     NaN      NaN   \n",
      "23          23  1953       6529.000    NaN      NaN      NaN     NaN      NaN   \n",
      "24          24  1954       5708.000    NaN      NaN      NaN     NaN      NaN   \n",
      "25          25  1955       6050.000    NaN      NaN      NaN     NaN      NaN   \n",
      "50          50  1982            NaN    NaN      NaN      NaN     NaN      NaN   \n",
      "\n",
      "    UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "0       NaN                            1.200  \n",
      "1       NaN                            2.700  \n",
      "2       NaN                            3.800  \n",
      "3       NaN                            3.900  \n",
      "4       NaN                            3.300  \n",
      "5       NaN                            4.200  \n",
      "6       NaN                            6.300  \n",
      "7       NaN                            6.200  \n",
      "12  173.000                           17.300  \n",
      "13  984.000                           80.800  \n",
      "14 1560.000                           94.900  \n",
      "15 1506.000                           92.400  \n",
      "16  869.000                           76.000  \n",
      "18      NaN                           23.100  \n",
      "19      NaN                           24.900  \n",
      "20      NaN                           24.500  \n",
      "21      NaN                           73.100  \n",
      "22      NaN                           94.100  \n",
      "23      NaN                           54.200  \n",
      "24      NaN                           45.300  \n",
      "25      NaN                           45.800  \n",
      "50      NaN                              NaN  \n",
      "CHOICE:      Unnamed: 0  YEAR  POUNDS GRADED  PRIME  CHOICE  SELECT  STNDRD  COMRCL  \\\n",
      "0            0  1930         69.000    NaN     NaN     NaN     NaN     NaN   \n",
      "1            1  1931        159.000    NaN     NaN     NaN     NaN     NaN   \n",
      "2            2  1932        208.000    NaN     NaN     NaN     NaN     NaN   \n",
      "3            3  1933        238.000    NaN     NaN     NaN     NaN     NaN   \n",
      "4            4  1934        262.000    NaN     NaN     NaN     NaN     NaN   \n",
      "5            5  1935        268.000    NaN     NaN     NaN     NaN     NaN   \n",
      "6            6  1936        450.000    NaN     NaN     NaN     NaN     NaN   \n",
      "7            7  1937        408.000    NaN     NaN     NaN     NaN     NaN   \n",
      "18          18  1948       2022.000    NaN     NaN     NaN     NaN     NaN   \n",
      "19          19  1949       2280.000    NaN     NaN     NaN     NaN     NaN   \n",
      "20          20  1950       2262.000    NaN     NaN     NaN     NaN     NaN   \n",
      "21          21  1951       6250.000    NaN     NaN     NaN     NaN     NaN   \n",
      "22          22  1952       8784.000    NaN     NaN     NaN     NaN     NaN   \n",
      "23          23  1953       6529.000    NaN     NaN     NaN     NaN     NaN   \n",
      "24          24  1954       5708.000    NaN     NaN     NaN     NaN     NaN   \n",
      "25          25  1955       6050.000    NaN     NaN     NaN     NaN     NaN   \n",
      "50          50  1982            NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "    UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "0       NaN                            1.200  \n",
      "1       NaN                            2.700  \n",
      "2       NaN                            3.800  \n",
      "3       NaN                            3.900  \n",
      "4       NaN                            3.300  \n",
      "5       NaN                            4.200  \n",
      "6       NaN                            6.300  \n",
      "7       NaN                            6.200  \n",
      "18      NaN                           23.100  \n",
      "19      NaN                           24.900  \n",
      "20      NaN                           24.500  \n",
      "21      NaN                           73.100  \n",
      "22      NaN                           94.100  \n",
      "23      NaN                           54.200  \n",
      "24      NaN                           45.300  \n",
      "25      NaN                           45.800  \n",
      "50      NaN                              NaN  \n",
      "SELECT:      Unnamed: 0  YEAR  POUNDS GRADED  PRIME  CHOICE  SELECT  STNDRD  COMRCL  \\\n",
      "0            0  1930         69.000    NaN     NaN     NaN     NaN     NaN   \n",
      "1            1  1931        159.000    NaN     NaN     NaN     NaN     NaN   \n",
      "2            2  1932        208.000    NaN     NaN     NaN     NaN     NaN   \n",
      "3            3  1933        238.000    NaN     NaN     NaN     NaN     NaN   \n",
      "4            4  1934        262.000    NaN     NaN     NaN     NaN     NaN   \n",
      "5            5  1935        268.000    NaN     NaN     NaN     NaN     NaN   \n",
      "6            6  1936        450.000    NaN     NaN     NaN     NaN     NaN   \n",
      "7            7  1937        408.000    NaN     NaN     NaN     NaN     NaN   \n",
      "18          18  1948       2022.000    NaN     NaN     NaN     NaN     NaN   \n",
      "19          19  1949       2280.000    NaN     NaN     NaN     NaN     NaN   \n",
      "20          20  1950       2262.000    NaN     NaN     NaN     NaN     NaN   \n",
      "21          21  1951       6250.000    NaN     NaN     NaN     NaN     NaN   \n",
      "22          22  1952       8784.000    NaN     NaN     NaN     NaN     NaN   \n",
      "23          23  1953       6529.000    NaN     NaN     NaN     NaN     NaN   \n",
      "24          24  1954       5708.000    NaN     NaN     NaN     NaN     NaN   \n",
      "25          25  1955       6050.000    NaN     NaN     NaN     NaN     NaN   \n",
      "50          50  1982            NaN    NaN     NaN     NaN     NaN     NaN   \n",
      "\n",
      "    UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "0       NaN                            1.200  \n",
      "1       NaN                            2.700  \n",
      "2       NaN                            3.800  \n",
      "3       NaN                            3.900  \n",
      "4       NaN                            3.300  \n",
      "5       NaN                            4.200  \n",
      "6       NaN                            6.300  \n",
      "7       NaN                            6.200  \n",
      "18      NaN                           23.100  \n",
      "19      NaN                           24.900  \n",
      "20      NaN                           24.500  \n",
      "21      NaN                           73.100  \n",
      "22      NaN                           94.100  \n",
      "23      NaN                           54.200  \n",
      "24      NaN                           45.300  \n",
      "25      NaN                           45.800  \n",
      "50      NaN                              NaN  \n",
      "UTILITY     Unnamed: 0  YEAR  POUNDS GRADED   PRIME    CHOICE   SELECT  STNDRD  \\\n",
      "0            0  1930         69.000     NaN       NaN      NaN     NaN   \n",
      "1            1  1931        159.000     NaN       NaN      NaN     NaN   \n",
      "2            2  1932        208.000     NaN       NaN      NaN     NaN   \n",
      "3            3  1933        238.000     NaN       NaN      NaN     NaN   \n",
      "4            4  1934        262.000     NaN       NaN      NaN     NaN   \n",
      "5            5  1935        268.000     NaN       NaN      NaN     NaN   \n",
      "6            6  1936        450.000     NaN       NaN      NaN     NaN   \n",
      "7            7  1937        408.000     NaN       NaN      NaN     NaN   \n",
      "18          18  1948       2022.000     NaN       NaN      NaN     NaN   \n",
      "19          19  1949       2280.000     NaN       NaN      NaN     NaN   \n",
      "20          20  1950       2262.000     NaN       NaN      NaN     NaN   \n",
      "21          21  1951       6250.000     NaN       NaN      NaN     NaN   \n",
      "22          22  1952       8784.000     NaN       NaN      NaN     NaN   \n",
      "23          23  1953       6529.000     NaN       NaN      NaN     NaN   \n",
      "24          24  1954       5708.000     NaN       NaN      NaN     NaN   \n",
      "25          25  1955       6050.000     NaN       NaN      NaN     NaN   \n",
      "50          50  1982            NaN     NaN       NaN      NaN     NaN   \n",
      "70          70  2002      21961.000 806.000 12334.000 8004.000     NaN   \n",
      "71          71  2003      21155.000 608.000 11580.000 8108.000   9.000   \n",
      "\n",
      "    COMRCL  UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
      "0      NaN      NaN                            1.200  \n",
      "1      NaN      NaN                            2.700  \n",
      "2      NaN      NaN                            3.800  \n",
      "3      NaN      NaN                            3.900  \n",
      "4      NaN      NaN                            3.300  \n",
      "5      NaN      NaN                            4.200  \n",
      "6      NaN      NaN                            6.300  \n",
      "7      NaN      NaN                            6.200  \n",
      "18     NaN      NaN                           23.100  \n",
      "19     NaN      NaN                           24.900  \n",
      "20     NaN      NaN                           24.500  \n",
      "21     NaN      NaN                           73.100  \n",
      "22     NaN      NaN                           94.100  \n",
      "23     NaN      NaN                           54.200  \n",
      "24     NaN      NaN                           45.300  \n",
      "25     NaN      NaN                           45.800  \n",
      "50     NaN      NaN                              NaN  \n",
      "70     NaN      NaN                           83.800  \n",
      "71     NaN      NaN                           82.200  \n",
      "Unnamed: 0                          0\n",
      "YEAR                                0\n",
      "POUNDS GRADED                       1\n",
      "PRIME                              22\n",
      "CHOICE                             17\n",
      "SELECT                             17\n",
      "STNDRD                             30\n",
      "COMRCL                             21\n",
      "UTILITY                            19\n",
      "%  of FEDERAL  SLAUGHTER\\t BEEF     1\n",
      "dtype: int64\n",
      "(84, 10)\n",
      "['Unnamed: 0', 'YEAR', 'POUNDS GRADED', 'PRIME', 'CHOICE', 'SELECT', 'STNDRD', 'COMRCL', 'UTILITY', '%  of FEDERAL  SLAUGHTER\\t BEEF']\n",
      "8749.835820895523\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (62) does not match length of index (84)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m imputer \u001b[38;5;241m=\u001b[39m KNNImputer(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     35\u001b[0m arr \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[1;32m---> 37\u001b[0m \u001b[43mdatasetBeef\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPRIME\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03mfor key in beefFill:\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    mn = datasetBeef[key].mean()##Omplim amb la mitja\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    datasetBeef[key] = datasetBeef[key].fillna(mn)\"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4538\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (62) does not match length of index (84)"
     ]
    }
   ],
   "source": [
    "#Esborrar els valors nulls que queden, si falta més del 50% esborrem la colummna, sino fem mitja o posem 0's.\n",
    "#Buscar valors nulls a les columnes\n",
    "##Beef\n",
    "print(\"POUNDS GRADED: \",datasetBeef.loc[datasetBeef['POUNDS GRADED'].isnull().values])\n",
    "print(\"%  of FEDERAL  SLAUGHTER\\t BEEF: \",datasetBeef.loc[datasetBeef['%  of FEDERAL  SLAUGHTER\\t BEEF'].isnull().values])\n",
    "print(\"PRIME: \", datasetBeef.loc[datasetBeef['PRIME'].isnull().values])\n",
    "print(\"CHOICE: \",datasetBeef.loc[datasetBeef['CHOICE'].isnull().values])\n",
    "print(\"SELECT: \",datasetBeef.loc[datasetBeef['SELECT'].isnull().values])\n",
    "print(\"UTILITY\",datasetBeef.loc[datasetBeef['UTILITY'].isnull().values])\n",
    "\n",
    "#Esborrar fila 1982 completament nula, ja  que només és una fila i fer la mitja no sería representatiu\n",
    "datasetBeef = datasetBeef.loc[datasetBeef['YEAR'] != \"1982\"]\n",
    "\n",
    "nullCounter(datasetBeef)\n",
    "\n",
    "\n",
    "beefDrop, beefFill = columnSelector(datasetBeef)\n",
    "\n",
    "print(beefFill)\n",
    "\n",
    "datasetBeef.drop(columns=beefDrop, inplace=True) ##Eliminem les columnes\n",
    "print(datasetBeef[\"CHOICE\"].mean())\n",
    "\n",
    "###Trying sklearn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "#imp_mean = IterativeImputer(random_state=0)\n",
    "#imp_mean.fit([datasetBeef[\"PRIME\"]])\n",
    "#imp_mean.transform([datasetBeef[\"PRIME\"]])\n",
    "X = [datasetBeef[\"PRIME\"]]\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "arr = imputer.fit_transform(X)\n",
    "\n",
    "datasetBeef[\"PRIME\"] = arr[0]\n",
    "\"\"\"\n",
    "for key in beefFill:\n",
    "    mn = datasetBeef[key].mean()##Omplim amb la mitja\n",
    "    datasetBeef[key] = datasetBeef[key].fillna(mn)\"\"\"\n",
    "print(\"-------------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POUNDS GRADED</th>\n",
       "      <th>PRIME</th>\n",
       "      <th>CHOICE</th>\n",
       "      <th>SELECT</th>\n",
       "      <th>STNDRD</th>\n",
       "      <th>COMRCL</th>\n",
       "      <th>UTILITY</th>\n",
       "      <th>%  of FEDERAL  SLAUGHTER\\t BEEF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1930</td>\n",
       "      <td>69.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1931</td>\n",
       "      <td>159.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1932</td>\n",
       "      <td>208.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1933</td>\n",
       "      <td>238.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1934</td>\n",
       "      <td>262.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>79</td>\n",
       "      <td>2011</td>\n",
       "      <td>20342.000</td>\n",
       "      <td>717.000</td>\n",
       "      <td>13170.000</td>\n",
       "      <td>6204.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>80.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>2012</td>\n",
       "      <td>19952.000</td>\n",
       "      <td>703.000</td>\n",
       "      <td>12889.000</td>\n",
       "      <td>6102.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>79.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>81</td>\n",
       "      <td>2013</td>\n",
       "      <td>19755.000</td>\n",
       "      <td>758.000</td>\n",
       "      <td>13038.000</td>\n",
       "      <td>5788.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>79.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>82</td>\n",
       "      <td>2014</td>\n",
       "      <td>19234.000</td>\n",
       "      <td>842.000</td>\n",
       "      <td>13157.000</td>\n",
       "      <td>5067.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>18.000</td>\n",
       "      <td>80.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>83</td>\n",
       "      <td>2015</td>\n",
       "      <td>23720.000</td>\n",
       "      <td>999.000</td>\n",
       "      <td>13409.000</td>\n",
       "      <td>3971.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>19.000</td>\n",
       "      <td>80.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  YEAR  POUNDS GRADED   PRIME    CHOICE   SELECT  STNDRD  \\\n",
       "0            0  1930         69.000     NaN       NaN      NaN     NaN   \n",
       "1            1  1931        159.000     NaN       NaN      NaN     NaN   \n",
       "2            2  1932        208.000     NaN       NaN      NaN     NaN   \n",
       "3            3  1933        238.000     NaN       NaN      NaN     NaN   \n",
       "4            4  1934        262.000     NaN       NaN      NaN     NaN   \n",
       "..         ...   ...            ...     ...       ...      ...     ...   \n",
       "79          79  2011      20342.000 717.000 13170.000 6204.000  68.000   \n",
       "80          80  2012      19952.000 703.000 12889.000 6102.000  63.000   \n",
       "81          81  2013      19755.000 758.000 13038.000 5788.000  11.000   \n",
       "82          82  2014      19234.000 842.000 13157.000 5067.000   8.000   \n",
       "83          83  2015      23720.000 999.000 13409.000 3971.000   3.000   \n",
       "\n",
       "    COMRCL  UTILITY  %  of FEDERAL  SLAUGHTER\\t BEEF  \n",
       "0      NaN      NaN                            1.200  \n",
       "1      NaN      NaN                            2.700  \n",
       "2      NaN      NaN                            3.800  \n",
       "3      NaN      NaN                            3.900  \n",
       "4      NaN      NaN                            3.300  \n",
       "..     ...      ...                              ...  \n",
       "79   3.000   16.000                           80.100  \n",
       "80   3.000   15.000                           79.700  \n",
       "81   4.000   16.000                           79.700  \n",
       "82   4.000   18.000                           80.900  \n",
       "83   3.000   19.000                           80.900  \n",
       "\n",
       "[84 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetBeef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBeef.to_csv(\"data/BeefDataset.csv\")\n",
    "datasetBeef = load_dataset(\"data/BeefDataset.csv\")\n",
    "for line in datasetBeef.columns:\n",
    "    print(line, type(datasetBeef[line][0]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Per visualitzar les primeres 5 mostres de la BBDD:\")\n",
    "datasetBeef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nullCounter(datasetBeef)\n",
    "datasetBeef[50:80]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Per veure estadístiques dels atributs numèrics de la BBDD:\")\n",
    "datasetBeef.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostrem atribut 0\n",
    "#plt.figure()\n",
    "datasetBeef.plot(x = 'YEAR', y = 'POUNDS GRADED')\n",
    "#ax = plt.scatter(x[:,0], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBeef.plot(x = 'YEAR', y = 'PRIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBeef.plot(x = 'YEAR', y = 'COMRCL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBeef = datasetBeef.values\n",
    "print(datasetBeef.shape)\n",
    "x = dataBeef[:, :19]\n",
    "y = dataBeef[:, 9]\n",
    "index = datasetBeef.columns[:10]\n",
    "\n",
    "#print(x)\n",
    "print(y)\n",
    "#print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(index)):\n",
    "    if i==len(index)-1:\n",
    "        break\n",
    "    plt.figure()\n",
    "    plt.scatter(x[:, i], y)\n",
    "    plt.title(index[i])\n",
    "    plt.ylabel(\"TOTAL POUNDS\")\n",
    "    plt.xlabel(index[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histograma de l'atribut 0\")\n",
    "plt.xlabel(\"Attribute Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "hist = plt.hist(x[:,2], bins=11, range=[np.min(x[:,2]), np.max(x[:,2])], histtype=\"bar\", rwidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(index)):\n",
    "    if i==len(index)-1:\n",
    "        break\n",
    "    plt.figure()\n",
    "    #plt.scatter(x[:, i], y)\n",
    "    plt.title(\"Histograma \" + index[i])\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xlabel(index[i])\n",
    "    hist = plt.hist(x[:,i], bins=11, range=[np.min(x[:,i]), np.max(x[:,i])], histtype=\"bar\", rwidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També podem estudiar la correlació entre els diferents atributs per tal de saber si estan correlacionats entre ells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Mirem la correlació entre els atributs d'entrada per entendre millor les dades\n",
    "correlacio = datasetBeef.corr()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "ax = sns.heatmap(correlacio, annot=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "També podem utilitzar la funció pairplot per tal de veure els atributs que estan relacionats entre si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mirem la relació entre atributs utilitzant la funció pairplot\n",
    "relacio = sns.pairplot(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Així doncs ara podreu respondre a les següents preguntes:\n",
    "\n",
    "1. Quin és el tipus de cada atribut? \n",
    "2. Quins atributs tenen una distribució Guassiana?\n",
    "3. Quin és l'atribut objectiu? Per què?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (B): Primeres regressions\n",
    "\n",
    "Per a aquest primer apartat es calcularà l'error quadràtic mitjà només del regressor per a cada un dels atributs de la base de dades, determinant aquell atribut pel qual l'error quadràtic mitjà (entre el valor predit i el real, per a cada mostra) és més baix. \n",
    "\n",
    "A continuació se us dona una funció auxiliar per a calcular l'error quadràtic mitjà:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def mean_squeared_error(y1, y2):\n",
    "    # comprovem que y1 i y2 tenen la mateixa mida\n",
    "    assert(len(y1) == len(y2))\n",
    "    mse = 0\n",
    "    for i in range(len(y1)):\n",
    "        mse += (y1[i] - y2[i])**2\n",
    "    return mse / len(y1)\n",
    "\n",
    "mean_squeared_error([1,2,3,4], [1,2,1,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per a agilitzar els càlculs es recomana utilitzar la llibreria numpy. Aquesta llibreria ens permet processar vectors sencers a la vegada de manera eficient i en paral·lel. Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #importem la llibreria\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "vector1 = np.array([1,2,3,4]) # convertim llista de python a numpy array\n",
    "vector2 = np.array([1,2,1,4]) \n",
    "\n",
    "# podem sumar dos vectors element a element\n",
    "print(\"Suma vector1 + vector2 \", vector1 + vector2)\n",
    "\n",
    "# podem sumar tots els valors d'un vector\n",
    "print(\"Suma valors vector1 \", vector1.sum())\n",
    "\n",
    "# calculem la mitjana\n",
    "print(\"Mitjana vector1\", vector1.mean())\n",
    "\n",
    "# utilitzem un vector com a índex de l'altre\n",
    "# vector3 = vector1  # necesitem fer una copia del vector per no modificar el original\n",
    "vector3 = vector1.copy()\n",
    "vector3[vector2 == 1] = 5\n",
    "print(\"Vector1 amb un 5 on el Vector2 te 1s \", vector3)\n",
    "\n",
    "# es pot utilitzar numpy per a calcular el mse\n",
    "def mse(v1, v2):\n",
    "    return ((v1 - v2)**2).mean()\n",
    "\n",
    "print(\"MSE: \", mse(vector1, vector2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per a la regressió podeu utilitzar la llibreria sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(x, y):\n",
    "    # Creem un objecte de regressió de sklearn\n",
    "    regr = LinearRegression()\n",
    "\n",
    "    # Entrenem el model per a predir y a partir de x\n",
    "    regr.fit(x, y)\n",
    "\n",
    "    # Retornem el model entrenat\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalment, si la funció `fit` del regressor logístic dónes l'error: `ValueError: Unknown label type: 'unknown'`, caldria afegir a la definició de l'atribut a trobar $y$ la crida a la funció `.astype('int')` per tal de obligar a que les dades siguin de tipus sencer, deixant el codi com segueix:\n",
    "\n",
    "`y = data[:,2].astype('int')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuació, es modificaran tots els atributs mitjançant **procediments de normalització (normal, estàndard)**, i s'avaluarà el rendiment del regressor après. Per a això, caldrà analitzar la mitja i variança de cada variable per totes les mostres, per identificar aquells valors que tenen una distribució normal, els preferits per fer regressió, i descartar altres atributs que no són representatius per fer la regressió, i que afegeixen soroll al model. \n",
    "\n",
    "Pel que fa a l'error resultant de la regressió, recordeu que es calcula fent la diferència entre el valor predit i el real al quadrat: així doncs, si les dades tenen valors grans (tipus 10^3), l'error al quadrat podria acabar sent 10^6. Per això és important normalitzar abans (escalar les dades a un rang més petit).\n",
    "\n",
    "<img src=\"images/standarization.png\">\n",
    "\n",
    "Podeu estandarditzar les dades amb les funcions mean i std de numpy i mostrar l'hisotgrama de nou. Recuperant l'exemple de l'apartat anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(x_train):\n",
    "    mean = x_train.mean(0)\n",
    "    std = x_train.std(0)\n",
    "    x_t = x_train - mean[None, :]\n",
    "    x_t /= std[None, :]\n",
    "    return x_t\n",
    "\n",
    "x_t = standarize(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara ja podeu comprovar la diferència entre entrenar amb els atributs estandaritzats i si aquells que tenen una distribució més semblant a la normal donen millors resultats. \n",
    "Finalment, s'aprendrà un model regressor tenint en compte tots aquells atributs que tenen una millor distribució de valors (lineal, això és, l'histograma de valors té forma de gaussiana), i es calcularà l'error assolit en la predicció. \n",
    "\n",
    "Recordeu que el valor sobre el que heu de fer la regressió queda al vostre criteri: **heu d'explicar a la memòria quin atribut heu fet servir, no hi ha una decisió única correcta, cal que doneu raons de per què heu triat l'atribut que hàgiu triat.**\n",
    "\n",
    "Així per exemple pode mirar:\n",
    "\n",
    "* Que l'objectiu de la regressió sigui un valor ordinal (1 > 2 > 3). Si no n'hi ha cap, explicar-ho a la memòria.\n",
    "\n",
    "* Que sigui útil en alguna aplicació real (per exemple predir si plourà és més interessant que predir el color dels núvols).\n",
    "\n",
    "* Que tingui certa variació (un atribut que és sempre 0, no té gaire interès)\n",
    "\n",
    "I en definitiva explicar el criteri a seguir, tant amb paraules com amb gràfiques (per exemple histograma), o estadístiques (per exemple la variança dels atributs) si escau.\n",
    "\n",
    "Un cop escollit l'atribut objectiu, caldrà justificar si l'error obtingut és, en proporció, menor que tenint en compte únicament el millor atribut identificat al primer punt. \n",
    "\n",
    "Podeu utilitzar les funcions hist de matplotlib per a calcular els histogrames. Exemple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Histograma de l'atribut 0\")\n",
    "plt.xlabel(\"Attribute Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "hist = plt.hist(x_t[:,0], bins=11, range=[np.min(x_t[:,0]), np.max(x_t[:,0])], histtype=\"bar\", rwidth=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o utilitzar les funcions de visualitzación del propi pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['attr2'],1).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ara que hem carregat les dades podem entrenar un regressor lineal per a aproximar la funció que les genera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Extraiem el primer atribut de x i canviem la mida a #exemples, #dimensions de l'atribut.\n",
    "# En el vostre cas, haureu de triar un atribut com a y, i utilitzar la resta com a x.\n",
    "atribut1 = x[:,0].reshape(x.shape[0], 1) \n",
    "regr = regression(atribut1, y) \n",
    "predicted = regr.predict(atribut1)\n",
    "\n",
    "# Mostrem la predicció del model entrenat en color vermell a la Figura anterior 1\n",
    "plt.figure()\n",
    "ax = plt.scatter(x[:,0], y)\n",
    "plt.plot(atribut1[:,0], predicted, 'r')\n",
    "\n",
    "# Mostrem l'error (MSE i R2)\n",
    "MSE = mse(y, predicted)\n",
    "r2 = r2_score(y, predicted)\n",
    "\n",
    "print(\"Mean squeared error: \", MSE)\n",
    "print(\"R2 score: \", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop mostrats de manera adient, (en forma de taula, i/o de gràfics si la dimensionalitat ho permet) els resultats aconseguits amb la regressió, avaluarem de manera independent la idonietat de cadascun dels atributs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Per a assegurar-nos que el model s'ajusta be a dades noves, no vistes, \n",
    "cal evaluar-lo en un conjunt de validacio (i un altre de test en situacions reals).\n",
    "Com que en aquest cas no en tenim, el generarem separant les dades en \n",
    "un 80% d'entrenament i un 20% de validació.\n",
    "\"\"\"\n",
    "def split_data(x, y, train_ratio=0.8):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    n_train = int(np.floor(x.shape[0]*train_ratio))\n",
    "    indices_train = indices[:n_train]\n",
    "    indices_val = indices[n_train:] \n",
    "    x_train = x[indices_train, :]\n",
    "    y_train = y[indices_train]\n",
    "    x_val = x[indices_val, :]\n",
    "    y_val = y[indices_val]\n",
    "    return x_train, y_train, x_val, y_val\n",
    "\n",
    "# Dividim dades d'entrenament\n",
    "x_train, y_train, x_val, y_val = split_data(x, y)\n",
    "\n",
    "for i in range(x_train.shape[1]):\n",
    "    x_t = x_train[:,i] # seleccionem atribut i en conjunt de train\n",
    "    x_v = x_val[:,i] # seleccionem atribut i en conjunt de val.\n",
    "    x_t = np.reshape(x_t,(x_t.shape[0],1))\n",
    "    x_v = np.reshape(x_v,(x_v.shape[0],1))\n",
    "\n",
    "    regr = regression(x_t, y_train)    \n",
    "    error = mse(y_val, regr.predict(x_v)) # calculem error\n",
    "    r2 = r2_score(y_val, regr.predict(x_v))\n",
    "\n",
    "    print(\"Error en atribut %d: %f\" %(i, error))\n",
    "    print(\"R2 score en atribut %d: %f\" %(i, r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quan es treballa en dades n-dimensionals (més d'un atribut), una opció és reduir la seva n-dimensionalitat aplicant un Principal Component Analysis (PCA) i quedar-se amb els primers 2 o 3 components, obtenint unes dades que (ara sí) poden ser visualitzables en el nou espai. Existeixen altres embeddings de baixa dimensionalitat on poder visualitzar les dades?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Així es podrà contestar a aquestes **preguntes**:\n",
    "\n",
    "1. Quin són els atributs més importants per fer una bona predicció?\n",
    "\n",
    "2. Amb quin atribut s'assoleix un MSE menor?\n",
    "\n",
    "3. Quina correlació hi ha entre els atributs de la vostra base de dades?\n",
    "\n",
    "4. Com influeix la normalització en la regressió?\n",
    "\n",
    "5. Com millora la regressió quan es filtren aquells atributs de les mostres que no contenen informació?\n",
    "\n",
    "6. Si s'aplica un PCA, a quants components es redueix l'espai? Per què?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartat (A): El descens del gradient  \n",
    "\n",
    "En aquest exercici, es tracta d'implementar en python el procés de descent del gradient explicat a les classes de teoria, i comparar-lo amb els resultats obtinguts amb l'apartat (B). \n",
    "\n",
    "$$J(w) = \\frac{1}{2m} \\left[ \\sum^m_{i=1}(f(x^{i}; w) - y^{i})^2 + \\lambda\\sum_{j=1}^{n}(w_{j}^2) \\right]$$\n",
    "\n",
    "Fixeu-vos que $J$ retorna el `mse`. Per a trobar $w_j$, repetir fins convergència:\n",
    "$$w_0 = w_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot 1$$\n",
    "$$w_j = w_j - \\alpha \\left[\\frac{1}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot x_{j}^{i} - \\frac{\\lambda}{m}w_{j} \\right]$$\n",
    "\n",
    "\n",
    "ó:\n",
    "\n",
    "$$w_{j} := w_{j} \\left(1-\\alpha \\frac{\\lambda}{m} \\right) - \\alpha\\frac{\\lambda}{m} \\sum_{i=1}^{m}(f(x^{i}; w)-y^{i}) \\cdot x_{j}^{i}$$\n",
    "\n",
    "On si considerem un regressor lineal (el model és una recta), llavors $w_0$ i $w_1$ representen, respectivament, la $b$ i $a$ de la fòrmula de la recta: \n",
    "\n",
    "$$h_\\theta(x^{(i)}) = ax + b$$\n",
    "\n",
    "$\\alpha$ és el learning rate, i $h_\\theta(x^{(i)})$ és la funció que fa la regressió, és a dir, la funció que prediu el valor de $y^{(i)}$ donat un(s) atribut(s) concret(s) $x^{(i)}$.\n",
    "\n",
    "Així, tenint calculat el model en l'últim punt del primer exercici, ja sabeu quin resultat hauríeu d'obtenir. O no, perquè la vostra implementació pot ser millor! En concret, es tracta de desenvolupar aquestes tasques:\n",
    "\n",
    "* Definir la funció de cost i del gradient\n",
    "\n",
    "* Estudiar com l'ús de regularitzadors afecta el resultat: overfitting, underfitting, etc. \n",
    "\n",
    "* Visualització de les dades a analitzar i explicació pas a pas del procediment   \n",
    "\n",
    "* Visualització del procés de descens de gradient \n",
    "\n",
    "* Modificar el learning rate i el nombre d'iteracions \n",
    "\n",
    "<img src=\"images/gradient_descent.png\">\n",
    "\n",
    "Per a la implementació us podeu basar en el següent esquelet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(object):\n",
    "    def __init__(self, w0, w1, alpha):\n",
    "        # Inicialitzem w0 i w1 (per ser ampliat amb altres w's)\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "        self.alpha = alpha\n",
    "\n",
    "        \n",
    "    def predict(self, x):\n",
    "        # implementar aqui la funció de prediccio\n",
    "        pass\n",
    "    \n",
    "    def __update(self, hy, y):\n",
    "        # actualitzar aqui els pesos donada la prediccio (hy) i la y real.\n",
    "        pass\n",
    "    \n",
    "    def train(self, max_iter, epsilon):\n",
    "        # Entrenar durant max_iter iteracions o fins que la millora sigui inferior a epsilon\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'últim pas serà validar el regressor trobat pel descent del gradient desenvolupat en aquest apartat visualment, aplicat a un model de recta i un model de pla. Per a això, caldrà considerar el millor atribut identificat en el primer punt de l'anterior entrega per visualitzar la línia regressora en 2D (podeu mostrar dades 2d amb la funció scatter). Després, dos dels atributs identificats a l'últim punt del primer exercici per visualitzar el pla regressor en 3D (En el cas 3D l’scatter s’ha de fer sobre una figura amb projecció 3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# Creem figura 3d\n",
    "from mpl_toolkits.mplot3d import axes3d, Axes3D\n",
    "# generem dades 3D d'exemple\n",
    "x_val = np.random.random((100, 2))\n",
    "y_val = np.random.random((100, 1))\n",
    "regr = regression(x_val, y_val)\n",
    "predX3D = regr.predict(x_val)\n",
    "\n",
    "# Afegim els 1's\n",
    "A = np.hstack((x_val,np.ones([x_val.shape[0],1])))\n",
    "w = np.linalg.lstsq(A,predX3D)[0]\n",
    "\n",
    "#Dibuixem\n",
    "#1r creem una malla acoplada a la zona de punts per tal de representar el pla\n",
    "malla = (range(20) + 0 * np.ones(20)) / 10 \n",
    "malla_x1 =  malla * (max(x_val[:,0]) - min(x_val[:,0]))/2 + min(x_val[:,0])\n",
    "malla_x2 =  malla * (max(x_val[:,1]) - min(x_val[:,1]))/2 + min(x_val[:,1])\n",
    "\n",
    "#la funcio meshgrid ens aparella un de malla_x1 amb un de malla_x2, per atot\n",
    "#element de mallax_1 i per a tot element de malla_x2.\n",
    "xplot, yplot = np.meshgrid(malla_x1 ,malla_x2)\n",
    "\n",
    "# Cal desnormalitzar les dades\n",
    "def desnormalitzar(x, mean, std):\n",
    "    return x * std + mean\n",
    "\n",
    "#ara creem la superficies que es un pla\n",
    "zplot = w[0] * xplot + w[1] * yplot + w[2]\n",
    "\n",
    "#Dibuixem punts i superficie\n",
    "plt3d = plt.figure('Coeficiente prismatico -- Relacio longitud desplacament 3D', dpi=100.0).gca(projection='3d')\n",
    "plt3d.plot_surface(xplot,yplot,zplot, color='red')\n",
    "plt3d.scatter(x_val[:,0],x_val[:,1],y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Així es podrà contestar a aquestes preguntes:\n",
    "\n",
    "1. Com influeixen tots els paràmetres en el procés de descens? Quins valors de learning rate convergeixen més ràpid a la solució òptima? Com influeix la inicialització del model en el resultat final? \n",
    "\n",
    "2. Quines funcions polinomials (de diferent grau, de diferents combinacions d'atributs, ...) heu escollit per ser apreses amb el vostre descens del gradient? quina ha donat el millor resultat (en error i rapidesa en convergència)?\n",
    "\n",
    "3. Utilitzeu el regularitzador en la fòrmula de funció de cost i descens del gradient i proveu polinomis de diferent grau. Com afecta el valor del regularitzador?\n",
    "\n",
    "3. Quina diferència (quantitativa i qualitativa) hi ha entre el vostre regressor i el de la llibreria ?\n",
    "\n",
    "4. Té sentit el model (polinomial) trobat quan es visualitza sobre les dades? \n",
    "\n",
    "5. Ajuda la visualització a identificar aquelles mostres per a les que el regressor obté els pitjors resultats de predicció? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
